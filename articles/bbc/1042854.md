<!--1681470782000-->
[ChatGPT：风起云涌的生成式AI和紧随而至的监管 从中国网信办新规看新赛道走向](https://www.bbc.com/zhongwen/simp/chinese-news-65274804)
------

<main role="main"><div></div><div><time dateTime="2023-04-14">5 分钟前</time></div><div><div><div data-e2e="media-player"><iframe src="https://www.bbc.com/ws/av-embeds/cps/zhongwen/simp/chinese-news-65274804/p0f1zj9c/zh-hans" title="多媒体播放器" allow="autoplay" scrolling="no" loading="lazy" allowfullscreen="" width="645.25" height="362.953125"></iframe><noscript><div><img alt="" src="https://images.weserv.nl/?url=ichef.bbci.co.uk/images/ic/512xn/p0f1zjl6.jpg" srcSet="https://ichef.bbci.co.uk/images/ic/240xn/p0f1zjl6.jpg 240w, https://ichef.bbci.co.uk/images/ic/320xn/p0f1zjl6.jpg 320w, https://ichef.bbci.co.uk/images/ic/480xn/p0f1zjl6.jpg 480w, https://ichef.bbci.co.uk/images/ic/624xn/p0f1zjl6.jpg 624w, https://ichef.bbci.co.uk/images/ic/800xn/p0f1zjl6.jpg 800w" aria-hidden="true"/><div><strong>你的器材不支持播放多媒体材料</strong></div></div></noscript></div><p>ChatGPT能写出《新闻之夜》的开场白，但人工智能可以拯救科技巨头吗？</p></div></div><div><p><b>本周，中国网信办发布了《生成式人工智能服务管理办法（征求意见稿）》，其中“利用生成式人工智能生成的内容应当体现社会主义核心价值观”，以及必须向网信办申报安全评估并且须进行算法备案等内容，引起关注。</b></p></div><div><p>正如特斯拉兴起，推高了中国电动车行业的热情；ChatGPT犹如一把大火，点燃了整个人工智能行业，仅仅几个月，百度推出文心一言，阿里巴巴推出通义千问，百川智能、商汤科技、昆仑万维也宣布要进入这个领域。</p></div><div><p>它们被统称为“生成式人工智能”（generative AI）。一句话概况，这种AI可以进行内容原创，通过算法来生成图像、文字、音乐，甚至代码和视频，而且不需要人工干预。</p></div><div><p>这一特点令用户既兴奋又害怕。比如，它可以创造出以假乱真的新闻图片，令虚假信息快速传播。中国和其它国家的监管新规，能让这条已经迅速火爆起来的赛道健康发展吗？</p></div><section aria-label="广告 2" aria-hidden="true" role="region" data-e2e="advertisement"><div id="dotcom-mpu"></div></section><div><ul role="list"><li role="listitem"><a href="/zhongwen/simp/science-63903800">BBC记者对话AI聊天机器人</a></li><li role="listitem"><a href="/zhongwen/simp/uk-61175018">“人工智能抢饭碗”  英国演员工会呼吁为艺人维权</a></li></ul></div><div><h2 id="为何这么快就进行监管" tabindex="-1">为何这么快就进行监管？</h2></div><div><p>“这么快就推出监管措施确实比较少见，比如P2P金融已经遍地都是，开始爆雷了才进行强监管。”一位要求匿名的中国人工智能从业者向BBC中文表示，生成式人工智能才爆发不到半年，中国的相关应用才推出几周，就推出监管办法，之所以这么快主要有三个原因：生成式AI的伦理问题、破坏力，以及极快的进化速度。</p></div><div><p>伦理担忧几乎伴随着人工智能的每一步发展。联合国教科文组织发布的《人工智能伦理问题建议书》称，此类技术极具侵入性，它们侵犯人权和基本自由，且被广泛使用。</p></div><div><p>这份建议书还表示，该技术也带来了前所未有的新挑战：性别和种族偏见增加，对隐私、尊严和行动力的重大威胁，大规模监控的风险，以及在执法中越来越多地使用不成熟的人工智能技术，如此种种。“直到现在，我们还没有通行的标准来应对这些问题。”</p></div><div><div><div><div><div data-e2e="image-placeholder"><div><div></div></div><img src="https://images.weserv.nl/?url=ichef.bbci.co.uk/news/640/cpsprodpb/16953/production/_127899429_gettyimages-991619332.jpg" alt="人类与机器人对话" width="976" height="549"/><p role="text"><span>图像来源，</span><span>Getty Images</span></p></div></div></div></div></div><div><p>伦理担忧对ChatGPT也同样存在——它已展现出“石破天惊”的智能化一面，对很多领域产生破坏性，比较直接的例子是有大学生用其生成论文并获得高分。</p></div><div><p>不仅如此，生成式人工智能进化速度极快，ChatGPT去年11月推出后，今年3月迭代出的GPT-4，不仅知识面更广、对答更流畅，开始能够读懂图片内容，在律师资格考试中拿下高分，而且具备自我反思的能力。</p></div><div><p>甚至ChatGPT的开发者也表示，全社会只有有限的时间来决定如何对其监管。</p></div><div><p>《生成式人工智能服务管理办法（征求意见稿）》颇受关注的一条是，“利用生成式人工智能生成的内容应当体现社会主义核心价值观，不得含有颠覆国家政权、推翻社会主义制度，煽动分裂国家、破坏国家统一，宣扬恐怖主义、极端主义，宣扬民族仇恨、民族歧视，暴力、淫秽色情信息，虚假信息，以及可能扰乱经济秩序和社会秩序的内容。”</p></div><div><p>上述业内人士认为，至于外界讨论很多的，是出于防止政治风险的原因，“我认为是过度解读了。中国的AI企业没有冲动借助这一工具实现什么政治目的，反而在开发之初就会极力避免，担忧的方向应该反过来，有了生成式AI这一工具，在防颠覆、防分裂和大规模监控的应用，或可起到超出意料的效果。”</p></div><div><h2 id="中美欧监管有啥不同" tabindex="-1">中美欧监管有啥不同？</h2></div><div><p>目前来看，欧洲的监管速度和力度都走在前列，中国次之，美国最慢。</p></div><div><p>3月31日，意大利个人数据保护局宣布即日起暂时禁止使用ChatGPT，欧盟的多个国家也开始跟进，在整个欧盟层面也开始酝酿具体监管措施。</p></div><div><p>中国则在4月11日宣布推出上述管理办法，并对社会公开征求意见，意见反馈截止时间为2023年5月10日，照此估计正式实施应该在下半年。</p></div><div><p>但从目前条例上可以看出，该办法实施的是前置监管，尺度还是很严格。比如，&quot;利用生成式人工智能产品向公众提供服务前，应当按照相关规定向国家网信部门申报安全评估，并履行算法备案和变更、注销备案手续。</p></div><div><p>美国也有动作，4月5日美国总统拜登也在白宫与科技顾问讨论，AI给人类、社会和国家安全带来的风险和机遇，拜登说，“在我看来，科技公司有责任确保他们的产品在公开之前是安全的。”至于AI是否危险时，他回答，“还有待观察，有这种可能性。”</p></div><div><p>4月11日，美国商务部也开始正式公开征求意见，其中包括新人工智能模型在发布前是否应经过认证程序等内容。</p></div><div><div><div><div><div data-e2e="image-placeholder"><div><div></div></div><img src="https://images.weserv.nl/?url=ichef.bbci.co.uk/news/640/cpsprodpb/B94F/production/_121793474_militaryrobot.jpg" alt="波兰展示的一个侦察机器人" width="976" height="549"/><p role="text"><span>图像来源，</span><span>Getty Images</span></p></div></div><div><p>人工智能和机器人已经被军队在战场上试验使用。</p></div></div></div></div><div><p>另外值得一提的是中国正在酝酿的监管措施的适用范围——“研发、利用生成式人工智能产品，面向中华人民共和国境内公众提供服务的，适用本办法。”</p></div><div><p>中国中伦律师事务所的蔡鹏等人撰文分析，这一划定方法表明无论生成式AI公司的实体位于何处，只要其支持境内用户使用，均会被纳入监管规定。以ChatGPT为例，目前正在严厉打击来自中国大陆地区的账号注册、使用其服务，不排除是避免中国法律管辖的先手。</p></div><div><p>这一点也间接表明，未来在AI领域也会有一个“防火墙”存在，复制了互联网时代的格局。</p></div><div><p>上述业内人士也认为，中国和美国在人工智能时代，也会是泾渭分明的两个市场，如同互联网时代防火墙的隔阂，造成无论哪个赛道都发展出各自的巨头。</p></div><div><p>“而欧洲在互联网时代的发展是掉队的，因此他们没有获益的机会，却有受损的可能，因此在反垄断、保护隐私方面，很激进，到了人工智能时代，也一样。”</p></div><div><h2 id="监管是否会制约中国AI产业发展" tabindex="-1">监管是否会制约中国AI产业发展？</h2></div><div><p>有此一问，是因为过去几年中国一些行业经历疾风骤雨般的监管打压——教育培训行业被“一刀切”；互联网巨头们被约谈，遭遇罚款和拆分；房地产企业们脚踩“三道红线”后，债务违约，濒临破产，留下一地“烂尾楼”。</p></div><div><p>以至于今年马云回国的消息占据诸多媒体头条，侧面也反映出，企业对于监管的战战兢兢。</p></div><div><div><div><div><div data-e2e="image-placeholder"><div><div></div></div><img src="https://images.weserv.nl/?url=ichef.bbci.co.uk/news/640/cpsprodpb/14BFA/production/_120668948_gettyimages-640351119.jpg" alt="Two robot hands gently manipulate an origami paper crane" width="976" height="549"/><p role="text"><span>图像来源，</span><span>Getty Images</span></p></div></div></div></div></div><div><p>“短期来看不会阻碍，甚至还可能促进AI的发展。”上述业内人士解释，背后的逻辑是，中国企业长期对监管都紧绷着神经，尤其是人工智能，先天很敏感，企业心里知道早晚都要强监管，现在早点划定边界，反而可以更好发展。</p></div><div><p>值得一提的是，这份监管文件中也明确了对生成式AI产业的支持和鼓励态度，比如，“国家支持人工智能算法、框架等基础技术的自主创新、推广应用、国际合作，鼓励优先采用安全可信的软件、工具、计算和数据资源。”</p></div><div><p>在2017年中国政府还印发了《新一代人工智能发展规划》，提出了人工智能发展的战略目标；2022年，科技部等六部门印发了《关于加快场景创新以人工智能高水平应用促进经济高质量发展的指导意见》，明确提出鼓励在重点行业深入挖掘人工智能技术应用场景。</p></div><div><p>这些迹象表明，中国政府对待AI新产品的态度，并不像对于加密货币那样，要“一棒子打死”，而是希望在可控状态下进行发展。</p></div><div><h2 id="监管可能的漏洞" tabindex="-1">监管可能的漏洞</h2></div><div><p>相比于此前较低端的AI对话模型，比如网店客服，生成式AI则可以根据已有信息虚构内容，比如在中文互联网上，有人通过AI虚构出特朗普被捕时的照片，由于过于逼真，使部分网民信以为真。</p></div><div><p>中文互联网上，甚至有网友要求ChatGPT给出自己的简历，ChatGPT则直接&quot;撒谎&quot;，虚构出完全不存在的经历，甚至包含一系列虚假的论文标题及链接。</p></div><div><p>新的监管办法中称，“利用生成式人工智能生成的内容应当真实准确，并且要求提供者采取措施防止生成虚假信息。”</p></div><div><p>“与其说漏洞，不如说不合理的地方。比如规定，AI生成内容应当真实准确。这就极不合理，因为它的本质就是一个创造性的工具，感觉就像规定一个画家或诗人，你的作品必须真实准确。”上述业内人士表示。</p></div><div><p>上述中伦律所的文章也提到这一点——一方面，部分生成式人工智能生成内容，例如人工智能创作的文章、图片、视频本就属于“不真实内容”，这是生成式人工智能本身的服务之一，如果强行要求人工智能生成内容必须真实准确则与该技术初衷不相符。另一方面，当前人工智能技术尚在发展阶段，单就技术而言，人工智能生成内容天然难以保证百分百真实准确。如果仅因为内容错误或者不完全而导致内容不准确，是否也构成&quot;虚假信息&quot;？因此&quot;虚假信息&quot;的范围有待进一步释明和细化。</p></div><div><p>而且，从条例的细则来看，对企业的要求是在3个月采取措施修正生成错误回答的AI模型，确保同样的错误不会再次发生，实际上也是给了企业不少的处理时间。</p></div><div><div><div><div><div data-e2e="image-placeholder"><div><div></div></div><img src="https://images.weserv.nl/?url=ichef.bbci.co.uk/news/640/cpsprodpb/EEEB/production/_116236116_gettyimages-1251214419.jpg" alt="Alibaba headquarters in Beijing。" width="976" height="549"/><p role="text"><span>图像来源，</span><span>Getty Images</span></p></div></div></div></div></div><div><h2 id="最担心什么" tabindex="-1">最担心什么？</h2></div><div><p>“作为这个行业的人，我最担心的不是监管，而是芯片问题。”上述从业者表示，很多人不知道训练AI需要很高算力，用到英伟达高端芯片，而美国去年一纸禁令，很可能制约中国在AI领域的发展。</p></div><div><p>2022年8月，美国对向中国出口的英伟达A100和H100等人工智能芯片实施限制。</p></div><div><p>具体而言，美国政府限制向中国、香港和俄罗斯等国家和地区，销售英伟达的A100图形处理器。A100已面世两年，它被广泛用于数据中心进行要求很高的人工智能计算。</p></div><div><p>英伟达公司还表示，受影响的还有公司即将推出的H100系列芯片，H100的制程更先进，对人工智能计算的提升更显著。</p></div><div><p>对于英伟达而言，中国市场是重中之重。它去年269亿美元的收入中，超过四分之一来自中国和香港。</p></div><div><p>英伟达表示，A100的用户包括阿里巴巴、腾讯和百度。这些公司运营着中国占主导地位的云计算服务，而且还能用于人工智能的算法和训练。</p></div></main>
