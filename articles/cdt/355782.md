<!--1675938439000-->
[红博士说｜中国如何缺席ChatGPT盛宴](https://chinadigitaltimes.net/chinese/692793.html)
------

<p>目录：</p><ol><li><p>ChatGPT 编年史</p></li><li><p>我们如何错过GPT盛宴</p></li><li><p>GPT大语言模型能实现AGI吗</p></li><li><p>连载话题预告</p></li></ol><div style="width:42%;float:right;padding-left:20px;"><div class="su-spoiler su-spoiler-style-fancy su-spoiler-icon-chevron-circle su-spoiler-closed" data-scroll-offset="0" data-anchor-in-url="no"><div class="su-spoiler-title" tabindex="0" role="button"><span class="su-spoiler-icon"></span>CDT 档案卡</div><div class="su-spoiler-content su-u-clearfix su-u-trim"><strong>标题：</strong>中国如何缺席ChatGPT盛宴<br><strong>作者：</strong>红博士<br><strong>来源：</strong><a href="https://mp.weixin.qq.com/s/V4D72elC8ezY1gDtjaZEUg" target="_blank" rel="noopener">微信公众号“红博士说”</a><br><strong>发表日期：</strong>2023.2.8<br><strong>主题归类：</strong><a href="https://chinadigitaltimes.net/chinese/tag/ChatGPT" target="_blank">ChatGPT</a><br><strong>CDS收藏：</strong><a href="https://chinadigitaltimes.net/space/%E5%85%AC%E6%B0%91%E9%A6%86" target="_blank" rel="noopener">公民馆</a><br><strong>版权说明：</strong>该作品版权归原作者所有。中国数字时代仅对原作进行存档，以对抗中国的网络审查。<a href="https://chinadigitaltimes.net/chinese/copyright">详细版权说明</a>。</div></div></div><p><img decoding="async" alt="file" data-src="https://chinadigitaltimes.net/chinese/files/2023/02/image-1675938423426.png" class="lazyload" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h3>ChatGPT编年史</h3><p>我们来梳理一个时间轴。ChatGPT是对话式UI + GPT–3.5系列模型，我们以最具代表性的论文、模型、API为主线，梳理到今天。</p><p>2020之前</p><ul><li><p>2017年6月，Google发布Transformer论文。</p></li><li><p>2017年6月，7月，OpenAI发布人类喜好的强化学习算法、PPO算法，都是ChatGPT用到的算法。</p></li><li><p>2018年6月，OpenAI发布GPT-1.</p></li><li><p>2018年11月，Google发布BERT，此后NLP领域主要基于这个框架研究下游任务。</p></li><li><p>2019年2月，OpenAI发布GPT-2，OpenAI获得了自信，此后专注于GPT.</p></li></ul><p>2020年</p><ul><li><p>年初，Covid-19爆发。<strong>中国闭关</strong>。</p></li><li><p>1月，OpenAI发布语言模型的Scaling Law（概念：模型能力跟参数规模、数据规模强相关），OpenAI获得了在数据和参数规模上Scaling-up的信心。</p></li><li><p>5月，GPT-3论文发布。</p></li><li><p>6月，<strong>GPT-3 API发布</strong>。</p></li><li><p>9月，ChatGPT的关键原型算法相关论文发布。</p></li><li><p>12月，欧洲机构发布用于GPT-3复现的开源数据集。</p></li></ul><p>2021年</p><ul><li><p>7月，OpenAI发布Copilot原型算法。</p></li><li><p>8月，Codex API发布。</p></li><li><p>11月，<strong>GPT-3 API Public Release，不对中国开放</strong>。</p></li><li><p><strong>中国闭关</strong>。</p></li></ul><p>2022年</p><ul><li><p>1月，GPT-3.5 API (text-davinci-002)发布，该模型经过Github代码的训练加持，推理能力显著提升（该假设的因果关系待学术界论证），经过Alignment技术的加持，Follow人类指令的能力显著提升，输出结果有用性和无害性显著提升。</p></li><li><p>3月，GPT-3.5论文发布，公开Alignment算法。</p></li><li><p>5月，OpenAI Codex已经被70个应用使用，包括微软收购的Github的Copilot.</p></li><li><p>8月，Stability AI开源StableDiffusion，文生图的算法的效果可用、速度可行、代码开源同时发生，引爆图片生成。一时间，在中国，AIGC似乎就是图片生成的代名词。</p></li><li><p>9月，Sequoia Capital发布Generative AI: A Creative New World博客。</p></li><li><p>中国研究人员和开发者，没有OpenAI的API权限。但图片生成却人人都可以尝试，于是互联网似乎只注意到了图片生成，对GPT大语言模型的关注度进一步下降。</p></li><li><p>经过接近一年的API接入和UI探索、近一年的思维链（Chain of Thought）等Prompt Engineering技术试错、模型加速等技术（如Flash Attention、Fixed-Point）带来的成本和延迟下降，GPT-3.5的模型潜力得到开发（变得Better、Faster and Cheaper）, Copy.ai, Jasper等文本生成类公司的产品逐渐成熟。</p></li><li><p>11月，OpenAI发布GPT3.5 API的新模型(text-davinci-003).</p></li><li><p><strong>12月1日，ChatGPT发布</strong>。Musk等名流开始谈论ChatGPT，引爆英文互联网。</p></li><li><p>12月初，中国互联网的自媒体逐渐开始讨论ChatGPT，主要以翻译twitter的方式。知乎上有学者开始反思。一周后，关注指数下降，两个月来只剩下AI自媒体把ChatGPT作为自己的主要关注内容。</p></li><li><p><strong>中国闭关</strong>。</p></li></ul><p>2023年</p><ul><li><p>1月，微软宣布投资OpenAI数十亿美元，并将GPT加入全家桶。</p></li><li><p>2月，中国春节结束，微软和Google你方唱罢我登场，纳斯达克财报季，AI被反复提起。中国互联网是认识微软的，ChatGPT引爆中国互联网，关注指数飙升。</p></li><li><p><strong>中国开放</strong>。</p></li></ul><p>值得注意的是，中国因为疫情闭关的三年，正是OpenAI的GPT发展、壮大、产品化的三年。</p><h3>我们如何错过GPT盛宴？</h3><p>历史回顾完了，那么为什么我们（中国，尤其是AI社区）没有更早地意识到，OpenAI技术在应用层面的突破性？</p><p>意识到问题需要同时具备哪些条件：</p><ol><li><p>能够看且懂OpenAI、DeepMind、Google等机构的论文（代表人群：研究员）</p></li><li><p>能够使用OpenAI的API探索论文里的模型 （代表人群：研究员里的尝鲜者）</p></li><li><p>对硅谷的敏感性，经常看大家在用OpenAI的API做什么产品 （代表人群：VC）</p></li></ol><p>这三类人在中国，我们粗估一下，第一类，大概有1/100,000，第二类大概是第一类里的1/1,000，第三类大概是1/1,000,000. 三个条件，缺少一个，都无法意识到OpenAI发展到哪一步了。有哪个团队汇集了这三种人，并且他们有充分的碰撞？有哪个人是具备了这三种属性？&nbsp;雪上加霜的是，研究人员三年来被封在国内，没有出国参加过学术会议交流，甚至我猜很多人连线上会议都没有参加，很多东西我们从论文上是看不到的。</p><p>我们继续深挖。第一类人群中，又分成NLP（自然语言处理）研究人员，其他AI研究人员（比如计算机视觉、语音识别、机器学习）。</p><p>中国NLP的研究群体里，基本上是把语言模型（尤其是BERT，而不是GPT）拿去应用在NLP的各种下游任务上，在学术界就是刷榜发论文，在工业界，就是拿去做客服机器人、写稿机器人、角色扮演机器人，研究方法也完全不同于GPT精髓——Scaling-up和Alignment。（几乎）没有人是把大语言模型（LLM）当做通用人工智能（AGI）的一种可能性来研究的。</p><p>其他AI研究人员，比如计算机视觉，大部分人还是专注在图像上，即使是用Transformer，也是解决图像的问题，比如用Transformer来做自动驾驶、图像生成等。即使是Tesla AutoPilot的AI主管Karpathy。Karpathy在2022年上半年从Tesla裸辞，以独立研究员的身份，投身于大语言模型。</p><p>Karpathy曾经说他过去十年痴迷于AI中取得最快进展的方向，并且曾经对语言模型非常感兴趣，但是却忽视了scaling up的力量，那就是简单的Objective（next word）+简单的结构（Transformer）+ 足够的参数+足够的数据(web text)，一个语言模型可以涌现出在小规模状态下看不到的能力，他曾像其他人一样（他应该指早期的OpenAI），一度以为强化学习是AGI的路径，到头来却发现大语言模型是看起来最有希望的路径。在此之前，语言模型的研究人员，把精力过多地放在了具体任务上。</p><p>再说AI领域的另一个重要群体——计算机视觉（Computer Vision)群体。在2012年开始的深度学习浪潮里，计算机视觉一直是应用最广、商业化最成功的方向，吸引了太多AI研究员的精力，从图像分类、检测、分割到识别，从图像到视频，从高层视觉到底层视觉，我们在卷积神经网络上卷出了一个又一个新高度。一个YOLO目标检测框架，被迭代到原作者都放弃了，还有人给推到了v7版本。最具代表性的是计算机视觉的登月工程——自动驾驶，它需要成像、识别、合成、建图、规划等几乎所有的视觉AI技术加持，从CNN时代到Transformer时代，不断地拉更多的人下水，但直到今天，全自动驾驶的方案仍未收敛。马斯克定义的问题是对的，自动驾驶是一个real-world AI问题，但显然特斯拉的方案并没有为全自动驾驶准备好。</p><p>NLP圈的小家碧玉，CV圈的隔行隔山，疫情闭关三年，互联网信息不通。这些因素叠加起来，整个中文世界，形成了一个信息茧房。10年来，我们以为自己积攒的AI算法、数据、应用的优势，如今变成中美巨大的鸿沟。这个时候，我们甚至没有一个新闻调查，把这件事的来龙去脉，挖它个底朝天。</p><p>另一个问题是，我们的中文互联网不足以提供高质量的训练数据。什么是高质量的数据？比如维基百科、高质量的活跃论坛、专业新闻、学术论文、高质量代码、图书。</p><p>我们看看GPT–3的训练数据是什么。权重最大的数据集是OpenWebText（开源版本）,数据是从Reddit论坛上收集的URL，再把内容抓取下来。Common Crawl是一个开放的互联网数据存档（英文占一半，中文大概5%）。其他一些代表性的数据包括Wikipedia维基百科，Books开放图书，Stack Exchange技术问答社区，Github 代码，ArXiv论文，RealNew新闻存档，PubMed医疗数据。可以看到，由中文互联网产生的数据，比例低到可以忽略。这也是困扰很多试图训练中文大模型的问题，但实际上，ChatGPT的用中文沟通的能力，已经远超那些专门的中文大语言模型了，背后原因是GPT隐式学到的翻译能力。</p><p>没有好的中文数据，我们就只能搭全球互联网的数据顺风车。上面这些优质数据的产生，需要开放的社区，我们似乎无解。</p><h3>GPT大语言模型能实现AGI吗？</h3><p>基于GPT的LLM，仅仅依赖语言，大概率无法实现AGI，而只是”通往AGI的高速公路的一个出口（Yann Lecun）“。但LLM足以把互联网基础设施搞个天翻地覆，它同时具备了Logic和Memory。Logic是推理能力，Memory是对高频知识的记忆，显然Memory可以分为片上和片外，片上有限，片外无限。下一步，我们只需要专注于把LLM的Logic推到极致，把大部分低频Memory offload到模型以外，配以搜索等查询技术，就可以实现对整个互联网前后端的重构。我们远远没有吃尽scaling-law的红利，限制我们的，只有集成电路的摩尔定律和制造能力、能源的价格、数据的获取。</p><p>集成电路方面，以Chiplet为代表的系统摩尔定律还不够，人们需要能够scaling-up的Foundry。</p><p>能源方面，太阳能和风能 + 能源存储能够解决很多问题，更加激动人心的是以Helion为代表的核聚变技术，则有机会把能源价格降低一个量级，然后更多。</p><p>数据方面，目前的GPT模型依赖互联网文本数据，这会用尽，没关系，现实世界的数据是无限的。</p><h3>连载话题预告</h3><p>今天先写到这儿。</p><p>计划中：</p><ul><li><p>OpenAI的故事</p></li><li><p>AI Alignment</p></li><li><p>AI与资本主义</p></li><li><p>AI与教育</p></li><li><p>AGI时代的人</p></li></ul><p>By 红博士, 2023年2月8日</p><div class="addtoany_share_save_container addtoany_content addtoany_content_bottom"><div class="a2a_kit a2a_kit_size_32 addtoany_list" data-a2a-url="https://chinadigitaltimes.net/chinese/692793.html" data-a2a-title="红博士说｜中国如何缺席ChatGPT盛宴"><a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fchinadigitaltimes.net%2Fchinese%2F692793.html&amp;linkname=%E7%BA%A2%E5%8D%9A%E5%A3%AB%E8%AF%B4%EF%BD%9C%E4%B8%AD%E5%9B%BD%E5%A6%82%E4%BD%95%E7%BC%BA%E5%B8%ADChatGPT%E7%9B%9B%E5%AE%B4" title="Facebook" rel="nofollow noopener" target="_blank"></a><a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fchinadigitaltimes.net%2Fchinese%2F692793.html&amp;linkname=%E7%BA%A2%E5%8D%9A%E5%A3%AB%E8%AF%B4%EF%BD%9C%E4%B8%AD%E5%9B%BD%E5%A6%82%E4%BD%95%E7%BC%BA%E5%B8%ADChatGPT%E7%9B%9B%E5%AE%B4" title="Twitter" rel="nofollow noopener" target="_blank"></a><a class="a2a_button_telegram" href="https://www.addtoany.com/add_to/telegram?linkurl=https%3A%2F%2Fchinadigitaltimes.net%2Fchinese%2F692793.html&amp;linkname=%E7%BA%A2%E5%8D%9A%E5%A3%AB%E8%AF%B4%EF%BD%9C%E4%B8%AD%E5%9B%BD%E5%A6%82%E4%BD%95%E7%BC%BA%E5%B8%ADChatGPT%E7%9B%9B%E5%AE%B4" title="Telegram" rel="nofollow noopener" target="_blank"></a><a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fchinadigitaltimes.net%2Fchinese%2F692793.html&amp;linkname=%E7%BA%A2%E5%8D%9A%E5%A3%AB%E8%AF%B4%EF%BD%9C%E4%B8%AD%E5%9B%BD%E5%A6%82%E4%BD%95%E7%BC%BA%E5%B8%ADChatGPT%E7%9B%9B%E5%AE%B4" title="Reddit" rel="nofollow noopener" target="_blank"></a><a class="a2a_button_whatsapp" href="https://www.addtoany.com/add_to/whatsapp?linkurl=https%3A%2F%2Fchinadigitaltimes.net%2Fchinese%2F692793.html&amp;linkname=%E7%BA%A2%E5%8D%9A%E5%A3%AB%E8%AF%B4%EF%BD%9C%E4%B8%AD%E5%9B%BD%E5%A6%82%E4%BD%95%E7%BC%BA%E5%B8%ADChatGPT%E7%9B%9B%E5%AE%B4" title="WhatsApp" rel="nofollow noopener" target="_blank"></a><a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fchinadigitaltimes.net%2Fchinese%2F692793.html&amp;linkname=%E7%BA%A2%E5%8D%9A%E5%A3%AB%E8%AF%B4%EF%BD%9C%E4%B8%AD%E5%9B%BD%E5%A6%82%E4%BD%95%E7%BC%BA%E5%B8%ADChatGPT%E7%9B%9B%E5%AE%B4" title="Email" rel="nofollow noopener" target="_blank"></a><a class="a2a_button_copy_link" href="https://www.addtoany.com/add_to/copy_link?linkurl=https%3A%2F%2Fchinadigitaltimes.net%2Fchinese%2F692793.html&amp;linkname=%E7%BA%A2%E5%8D%9A%E5%A3%AB%E8%AF%B4%EF%BD%9C%E4%B8%AD%E5%9B%BD%E5%A6%82%E4%BD%95%E7%BC%BA%E5%B8%ADChatGPT%E7%9B%9B%E5%AE%B4" title="Copy Link" rel="nofollow noopener" target="_blank"></a><a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share"></a></div></div>
