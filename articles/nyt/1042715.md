<!--1717146422000-->
[OpenAI称中俄利用其人工智能技术操纵舆论](https://cn.nytimes.com/technology/20240531/openai-influence-campaigns-report/)
------

<address>CADE METZ</address><time pudate="2024-05-31 11:31:07" datetime="2024-05-31 11:31:07">2024年5月31日</time><figure><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2024/05/30/multimedia/30openai-disinfo-zlkw/30openai-disinfo-zlkw-master1050.jpg" width="1050" height="700"><figcaption>OpenAI在旧金山的办公室。 <cite>Jason Henry for The New York Times</cite></figcaption></figure><section><p><a href="https://www.nytimes.com/2024/05/28/technology/openai-gpt4-new-model.html">OpenAI</a>周四表示，它发现并破坏了五个利用其生成式人工智能技术，以欺骗方式操纵世界各地公众舆论、影响地缘政治的线上活动。</p><p>OpenAI在一份关于秘密影响活动的报告中表示，这些活动由俄罗斯、中国、伊朗和以色列的国家行为体和私营公司实施。它们使用OpenAI的技术来生成社交媒体帖子、翻译和编辑文章、撰写标题和调试计算机程序，通常是为了赢得对政治活动的支持，或者在地缘政治冲突中左右公众舆论。</p><p>社交媒体研究人员表示，OpenAI的报告是一家大型人工智能公司首次披露其特定工具如何被用于此类在线欺骗。最近，生成式人工智能的兴起令人们对该技术可能如何助长<a href="https://www.nytimes.com/interactive/2024/05/19/technology/biased-ai-chatbots.html">在线虚假信息</a><a href="https://www.nytimes.com/2023/06/25/technology/ai-elections-disinformation-guardrails.html">产生疑问</a>，尤其是在<a href="https://cn.nytimes.com/world/20240111/election-disinformation-2024/">全球各地都在举行重大选举的年份</a>。</p><p>OpenAI的首席研究员本·尼莫说，在人们纷纷猜测此类活动中使用了生成式人工智能之后，该公司的目标是展示这项技术如何改变在线欺骗的现实。</p><p>“我们的案例研究提供了一些目前最广泛报道、持续时间最长的影响力活动的实例，”他说。</p><p>尼莫表示，这些活动经常使用OpenAI的技术发布政治内容，但该公司很难确定它们是针对特定的选举，还是只是为了挑拨人们。他还说，这些活动未能获得太多的关注，人工智能工具似乎没有扩大其覆盖面或影响力。</p><p>“这些影响力运作仍然难以吸引受众，”尼莫说。</p><p>但大西洋理事会数字法医研究实验室的高级主管格雷厄姆·布鲁基警告，随着生成式人工智能技术日益强大，在线虚假信息的格局也可能发生变化。本周，ChatGPT聊天机器人的制造商OpenAI表示，它已经开始<a href="https://www.nytimes.com/2024/05/28/technology/openai-gpt4-new-model.html" title="Link: https://www.nytimes.com/2024/05/28/technology/openai-gpt4-new-model.html">训练一种新的旗舰人工智能模型</a>，将带来“更高水平的能力”。</p><p>“这是一种新型的工具，”布鲁基说。“它会产生什么影响，还有待观察。”</p><p>（《纽约时报》已<a href="https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html">起诉</a>OpenAI及其合作伙伴微软，称其侵犯了与人工智能系统相关新闻内容的版权。）</p><p>与谷歌、Meta和微软一样，OpenAI也提供在线聊天机器人和其他人工智能工具，这些工具可以撰写社交媒体帖子、生成逼真的图像和编写计算机程序。该公司在报告中表示，其工具已被用于研究人员追踪多年的影响力活动，包括被称为“二重身”的俄罗斯活动和被称为“垃圾邮件伪装”的中国活动。</p><p><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2024/05/30/business/30OPENAI-DISINFO-1/30OPENAI-DISINFO-1-jumbo.jpg"><small style="color: #999;">一个影响力活动在Telegram上发布的帖子，OpenAI说，这是利用它的工具生成的。</small></p><p>OpenAI表示，“二重身”利用OpenAI的技术，在X上用英语、法语、德语、意大利语和波兰语发表反乌克兰的评论。该公司的工具还被用于将支持乌克兰战争中俄罗斯一方的文章翻译、编辑成英语和法语，并将反乌克兰的新闻文章转化为Facebook帖子。</p><p>该公司表示，OpenAI的工具还被用于此前一直不为人知的俄罗斯攻击活动，主要是通过Telegram即时通讯服务针对乌克兰、摩尔多瓦、波罗的海国家和美国的人民。该活动利用人工智能，用俄语和英语对乌克兰战争、摩尔多瓦政治局势和美国政治发表评论。这项工作还使用了OpenAI工具来调试计算机代码，这些代码显然是为了自动向Telegram发布信息而设计的。</p><p>OpenAI表示，这些政治评论几乎没有得到回复和“点赞”。这些努力有时也不够成熟。有一次，该活动发布了明显由人工智能生成的文本。“作为一个人工智能语言模型，我在这里提供帮助，并提供所需的评论，”一篇帖子写道。还有几次，它用蹩脚的英语发帖，OpenAI称其为“糟糕的语法”。</p><p>“垃圾邮件伪装”长期以来一直被视为中国行动，OpenAI表示，它使用OpenAI技术调试代码，就如何分析社交媒体和研究时事寻求建议。该公司的工具还被用来在社交媒体上发布帖子，贬低中国政府的批评者。</p><p>伊朗的活动与一个名为国际虚拟媒体联盟的组织有关，该组织使用OpenAI工具制作和翻译长篇文章和标题，目标是在网上传播亲伊朗、反以色列和反美国的情绪。</p><p>OpenAI将以色列的活动称为“芝诺芝诺”，称其由一家管理政治活动的公司负责管理。它使用OpenAI技术生成虚构的人物和传记，在以色列、加拿大和美国的社交媒体服务上代替真实的人，并发布反伊斯兰信息。</p><p>OpenAI的报告称，虽然当今的生成式人工智能可以帮助提高政治活动的效率，但这些工具并没有<a href="https://www.nytimes.com/2024/04/02/technology/an-ai-researcher-takes-on-election-deepfakes.html" title="Link: https://www.nytimes.com/2024/04/02/technology/an-ai-researcher-takes-on-election-deepfakes.html">像许多人工智能专家预测的那样</a>，制造出大量令人信服的虚假信息。</p><p>“这表明，我们对人工智能支持的影响力操纵和人工智能支持的虚假信息的一些最大担忧尚未成为现实，”Graphika首席情报官杰克·斯塔布斯说。Graphika追踪社交媒体服务的操纵行为，并审查了OpenAI的调查结果。</p></section><footer><p>Cade Metz撰写有关人工智能、无人驾驶汽车、机器人、虚拟现实和其他技术新兴领域的新闻。<a rel="nofollow" target="_blank" href="https://www.nytimes.com/by/cade-metz">点击查看更多关于他的信息。</a></p><p>翻译：纽约时报中文网</p><a rel="nofollow" target="_blank" href="https://www.nytimes.com/2024/05/30/technology/openai-influence-campaigns-report.html">点击查看本文英文版。</a></footer>
