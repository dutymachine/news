<!--1704960422000-->
[2024大选年，一场“彻头彻尾的虚假信息灾难“？](https://cn.nytimes.com/world/20240111/election-disinformation-2024/)
------

<address>TIFFANY HSU, STUART A. THOMPSON, STEVEN LEE MYERS</address><time pudate="2024-01-11 03:55:33" datetime="2024-01-11 03:55:33">2024年1月11日</time><figure><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2024/01/11/multimedia/c11election-disinformation-2024-map/c11election-disinformation-2024-map-master1050.png" width="1050" height="630"><figcaption>根据咨询公司Anchor Change数据显示，全球选举日历包括至少38场选举，是未来至少24年选举活动最为密集的一年。 <cite></cite></figcaption></figure><section><p>据一些估计，约占一半全球人口的数十亿民众将在今年的重大选举中投票，这将构成当代记忆中规模最大、影响最深远的民主实践之一。而这些选举的结果将影响未来数十年的世界形势。</p><p>与此同时，虚假叙事和阴谋论已演变成一种日益严峻的全球威胁。</p><p>毫无依据的选举舞弊指控损害了人们对民主的信任。外国影响力活动经常针对两极分化的国内挑战而展开。人工智能助长了虚假信息的猖獗，扭曲了人们对现实的理解。而大型社交媒体公司还削减了防护措施并缩小了选举内容团队的规模。</p><p>“几乎所有民主政体都处于压力之下，这与技术无关，”智库布鲁斯金学会的高级研究员达雷尔·M·韦斯特说。“再加上虚假信息的影响，只会让许多麻烦趁虚而入。”</p><p>他说，这堪称一场“彻头彻尾的虚假信息灾难”。</p><p>潜在的代价是巨大的。</p><p>从大规模移民到气候破坏，从经济不平等到战争，“冷战”后盛行全球的民主制度正面临世界范围内日益严峻的挑战。许多国家在妥善应对这些考验时遭遇的困境削弱了人们对自由多元社会的信心，民粹主义者和强人领袖因而有了民意基础。</p><p>以俄罗斯和中国为首的专制国家往往通过赞助虚假信息宣传运动，利用政治不满情绪来推动破坏民主治理和领导的叙事。这些努力若取得成效，各地的选举可能就会对近来专制领袖崛起的趋势起到加速作用。</p><p><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2024/01/05/multimedia/ELECTIONS-DISINFO-Taiwan-kftg/ELECTIONS-DISINFO-Taiwan-kftg-master1050.jpg"><small style="color: #999;">台湾副总统、执政的民进党总统候选人赖清德本月在台北的一场竞选活动中向支持者挥手致意。台湾正试图抵御中国的不实信息宣传。</small></p><p>支持克里姆林宫的莫斯科智库外交与国防政策委员会的负责人费奥多尔·A·卢基亚诺夫最近宣称，2024年“可能是西方自由派精英丧失对世界秩序控制的一年”。</p><p>技术政策公司Anchor Change创始人、曾在Facebook担任公共政策总监的凯蒂·哈巴斯表示，许多国家的政治体制以及<a href="https://www.nytimes.com/2023/09/09/world/europe/what-is-the-g20.html">20国集团</a>等政府间组织可能将迎来剧变。虚假信息不仅存在于社交媒体，也通过印刷物、广播和电视和口头传播，可能将破坏政治进程的稳定。</p><p>“到2025年，世界将变得非常不同，”她说。</p><p><b>咄咄逼人的国家行动</b></p><p><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2024/01/05/multimedia/00elections-disinfo-pakistan-mhjf/00elections-disinfo-pakistan-mhjf-master1050.jpg"><small style="color: #999;">去年，“巴基斯坦正义运动”支持者在伊斯兰堡参与力挺总理伊姆兰·汗的抗议集会。巴基斯坦选举将于2月进行。</small></p><p>在竞选活动中，虚假信息的最大来源之一是那些专制政府，它们试图诋毁民主作为全球治理模式的声誉。</p><p>近几个月来，研究人员和美国政府都认为俄罗斯、<a href="https://cn.nytimes.com/technology/20231215/pro-china-youtube-disinformation/">中国</a>和伊朗有可能试图采取影响行动，干扰其他国家的选举，包括今年的美国总统选举。数字安全公司“记录未来”的分析师布莱恩·利斯顿说，这些国家认为，未来一年是“在世界舞台上让我们难堪、利用社会分歧、破坏民主进程的真正机会”。该公司最近曾<a rel="noopener noreferrer" target="_blank" href="https://www.recordedfuture.com/aggressive-malign-influence-threatens-us-2024-elections">报道美国竞选面临的潜在威胁</a>。</p><p>该公司还调查了Meta<a href="https://www.nytimes.com/2023/12/07/technology/russia-disinformation-mike-tyson-priscilla-presley.html">去年首次发现</a>的俄罗斯影响力行动，该行动被称为“分身”，似乎冒充国际新闻机构，创建虚假账户，在美国和欧洲传播俄罗斯的宣传。“分身”似乎使用了广泛可用的人工智能工具，创建了专门报道美国政治的新闻媒体，名为“选举观察”和“我的骄傲”等。</p><p>散布在世界各地的虚假叙述往往由侨民社区分享的，或由国家支持的特工精心策划。专家预测，选举舞弊的说法将继续演变并产生影响，就像在2022年的美国和巴西，以及在2023年的阿根廷一样。</p><p><b>两极分化和极端主义的循环</b></p><p>日益两极化和好斗的政治环境正在滋生仇恨言论和错误信息，从而将选民进一步推向孤岛。在强化用户偏见的社交媒体算法帮助下，少数有动机的极端声音往往会淹没温和的大多数。</p><p>“我们正在重新定义关于言论的社会规范，以及如何让人们对自己的言论负责，无论是在线上还是线下，”哈巴思说。“关于如何在这个国家做到这一点，有很多不同的观点，更不用说全球了。”</p><p><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2024/01/05/multimedia/00elections-disinfo-hfgb/00elections-disinfo-hfgb-master1050.jpg"><small style="color: #999;">在印度，总理曾就人工智能的误导性内容发出警告，该国大选定于春季举行。</small></p><p>一些最极端的声音会在Telegram、<a rel="noopener noreferrer" target="_blank" href="https://www.pewresearch.org/short-reads/2023/02/17/key-facts-about-bitchute/">BitChute</a>和<a href="https://www.nytimes.com/2023/11/16/business/trump-media-truth-social-advertising-revenue.html">Truth social</a>等另类社交媒体平台上寻找彼此。监测威胁和误导信息的公司皮拉称，事先采取措施制止选民舞弊的呼吁最近在这些平台上成为潮流——从历史上看，这种舞弊在统计上是微不足道的。</p><p><a rel="noopener noreferrer" target="_blank" href="https://www.pyrratech.com/articles/case-study-alt-socials-role-in-influencing-narratives-around-u-s-election-validity">皮拉在一个案例研究中发现</a>，“这些说法的流行和接受程度只会越来越高”，甚至直接影响到选举政策和立法。</p><p>“这些阴谋正在政治精英中生根，他们正在利用这些叙事来赢得公众的好感，同时降低了他们本应维护的制度的透明度、制衡和平衡，”该公司的研究人员写道。</p><p><b>人工智能的风险与收益</b></p><p>根据芝加哥大学和斯坦福大学的一份<a rel="noopener noreferrer" target="_blank" href="https://www.gsb.stanford.edu/sites/default/files/publication/pdfs/white-paper-2023-ai-and-elections-best-practices_0.pdf">报告</a>，人工智能“为民主治理带来了希望”。关注政治的聊天机器人可以让选民了解关键问题，并更好地将选民与民选官员联系起来。</p><p>这项技术也可能成为虚假信息的载体。虚假的人工智能图像已经被用来传播阴谋论，例如有人毫无根据地断言，有一个用非白人<a href="https://www.nytimes.com/2022/02/15/world/europe/france-elections-pecresse-great-replacement.html">移民</a>来<a href="https://www.nytimes.com/2022/05/16/podcasts/the-daily/buffalo-shooting-replacement-theory.html">取代</a>欧洲白人的全球阴谋。</p><p><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2024/01/05/multimedia/00elections-disinfo-European-Parliament-lzkg/00elections-disinfo-European-Parliament-lzkg-master1050.jpg"><small style="color: #999;">欧洲议会选举将于6月举行，与此同时，欧盟将出台一项新的法律，旨在遏制具有腐蚀性的网络内容。</small></p><p>在公共政策研究所布伦南司法中心负责选举和政府项目的劳伦斯·诺顿还说，人工智能可以模仿大量来自选举办公室的材料，并将其广泛传播。或者，它可能会在最后阶段制造“<a href="https://www.nytimes.com/2023/03/25/us/politics/trump-october-surprise.html">10月惊奇</a>”，就像今年秋天斯洛伐克紧张的选举期间发布的带有人工智能干预迹象的<a rel="noopener noreferrer" target="_blank" href="https://www.wired.com/story/slovakias-election-deepfakes-show-ai-is-a-danger-to-democracy/">音频</a>那样。</p><p>“一段时间以来威胁着我们民主的所有事情，都有可能因为人工智能而变得更糟，”诺登在11月参加一个在线小组讨论时说。(在活动期间，组织者引入了一个<a rel="noopener noreferrer" target="_blank" href="https://www.youtube.com/watch?v=VH1rOylsoMo&t=2s">人工智能操纵的“诺登”</a>，以强调这项技术的能力。)</p><p>一些专家担心，<a href="https://www.nytimes.com/2023/10/28/business/media/ai-muddies-israel-hamas-war-in-unexpected-way.html">人工智能工具的存在本身</a>就可能削弱人们对信息的信任，使政治行为者能够抹去真实的内容。其他人则表示，目前的担忧被夸大了。智库美国外交关系委员会高级副会长詹姆斯·林赛说，人工智能“只是众多威胁之一”。</p><p>“我不会忽视所有散布错误信息或虚假信息的老派方式，”他说。</p><p><b>大型科技公司缩减保护措施</b></p><p><a rel="noopener noreferrer" target="_blank" href="https://www.unesco.org/sites/default/files/medias/fichiers/2023/11/unesco_ipsos_survey.pdf">联合国教科文组织</a>的调查显示，在计划于2024年举行大选的国家，虚假信息已成为绝大多数人关注的主要问题。社交媒体公司限制有害内容的努力曾在2016年美国总统大选后升级，然而最近已经<a href="https://www.nytimes.com/2023/02/14/technology/disinformation-moderation-social-media.html">逐渐减弱</a>，甚至完全逆转。</p><p>倡导组织“自由新闻”<a rel="noopener noreferrer" target="_blank" href="https://www.freepress.net/big-tech-backslide-report">最近的报告</a>显示，去年，Meta、YouTube和前身为Twitter的平台X缩减或重组了负责<a href="https://www.nytimes.com/2022/11/28/technology/twitter-misinformation-experts-hiring.html">检查危险或不准确材料</a>的团队。有些平台还提供了一些新功能，比如私人单向广播，这些功能特别难以监控。</p><p>自由新闻的高级法律顾问诺拉·贝纳维德兹说，这些公司在新的一年开始时“带宽很少，书面问责制很弱，而全球数十亿人在这些平台获取信息”——这不是维护民主的理想选择。</p><p><a href="https://www.nytimes.com/2022/08/14/business/media/on-tiktok-election-misinformation.html">TikTok</a>等较新的平台很可能会开始在政治内容中<a href="https://www.nytimes.com/2023/12/13/business/media/tiktok-politicians.html">发挥更大的作用</a>。新闻通讯初创公司Substack上月表示，不会在其平台上禁止纳粹符号和极端主义言论，并希望2024年的选举季成为“<a rel="noopener noreferrer" target="_blank" href="https://on.substack.com/p/in-the-2024-us-elections-vote-for">Substack选举</a>”。政界人士正计划在Twitch上进行<a rel="noopener noreferrer" target="_blank" href="https://www.washingtonpost.com/technology/2023/09/28/live-stream-twitch-politics-khanna/">直播活动</a>，该平台还将主持人工智能生成的拜登总统和特朗普前总统之间的辩论。</p><p>拥有Facebook、Instagram和WhatsApp的Meta在去年11月的一篇<a rel="noopener noreferrer" target="_blank" href="https://about.fb.com/news/2023/11/how-meta-is-planning-for-elections-in-2024/" title="Link: https://about.fb.com/news/2023/11/how-meta-is-planning-for-elections-in-2024/">博客文章</a>中表示，它“有能力在我们的平台上保护明年选举的公正性”。(上个月，公司任命的一个监督委员会对Meta的自动化工具及其对<a rel="noopener noreferrer" target="_blank" href="https://oversightboard.com/news/1109713833718200-oversight-board-issues-first-expedited-decisions-about-israel-hamas-conflict/">两个与以色列—哈马斯冲突有关视频</a>的处理提出了质疑。)</p><p>YouTube上个月<a rel="noopener noreferrer" target="_blank" href="https://blog.youtube/inside-youtube/supporting-2024-united-states-election/">写道</a>，其“专注选举的团队一直在不停地工作，以确保我们有正确的原则和系统。”该平台今年夏天表示，将<a rel="noopener noreferrer" target="_blank" href="https://www.npr.org/2023/06/02/1179864026/youtube-will-no-longer-take-down-false-claims-about-u-s-elections" title="Link: https://www.npr.org/2023/06/02/1179864026/youtube-will-no-longer-take-down-false-claims-about-u-s-elections">停止删除虚假的选民欺诈叙述</a>。（YouTube表示，它希望选民听到辩论各方的意见，但它指出，“这不是传播有害错误信息或宣传仇恨言论的免费通行证”。）</p><p>亿万富翁埃隆·马斯克于2022年底接管X后，<a href="https://www.nytimes.com/interactive/2023/10/27/technology/twitter-x-elon-musk-anniversary.html">此类内容在X上激增</a>。几个月后，亚历山德拉·波肯离开了负责该平台信任和安全运营的职位。波肯后来加入了内容审核公司WebPurify。她说，许多社交媒体公司严重依赖于不可靠的人工智能内容审核工具，让精简后的人力团队处于不断灭火的状态。</p><p>“选举诚信是一项巨大的努力，确实需要一个积极主动的战略，需要很多人力、很多智慧和作战室，”她说。</p></section><footer><p>Tiffany Hsu报道错误信息和虚假信息及其起源、动向和后果。她从事记者工作已超过20年。<a rel="nofollow" target="_blank" href="https://www.nytimes.com/by/tiffany-hsu">点击查看更多关于她的信息。</a></p><p>Stuart A. Thompson撰写有关虚假和误导性信息如何在网上传播及其如何影响世界各地人们的文章。他主要负责报道错误信息、虚假信息和其他误导性内容。<a rel="nofollow" target="_blank" href="https://www.nytimes.com/by/stuart-a-thompson">点击查看更多关于他的信息。</a></p><p>Steven Lee Myers为《纽约时报》报道关于虚假信息的新闻。他曾在华盛顿、莫斯科、巴格达和北京工作，驻北京期间，他对获得2021年普利策公共服务奖的报道有报道贡献。他著有《新沙皇：弗拉基米尔·普京的崛起和统治》(The New Tsar: The Rise and Reign of Vladimir Putin)一书。<a rel="nofollow" target="_blank" href="https://www.nytimes.com/by/steven-lee-myers">点击查看更多关于他的信息。</a></p><p>翻译：Harry Wong、晋其角</p><p><a rel="nofollow" target="_blank" href="https://www.nytimes.com/2024/01/09/business/media/election-disinformation-2024.html">点击查看本文英文版，</a></p></footer>
