<!--1701931022000-->
[监管人工智能的五种可能方式](https://cn.nytimes.com/technology/20231207/artificial-intelligence-regulation/)
------

<address>CECILIA KANG, ADAM SATARIANO</address><time pudate="2023-12-07 02:25:35" datetime="2023-12-07 02:25:35">2023年12月7日</time><figure><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2023/12/06/multimedia/06ai-approaches-schumer-gpzf/06ai-approaches-schumer-gpzf-master1050.jpg" width="1050" height="700"><figcaption>多数党领袖、纽约州参议员查克·舒默主持了多场于9月召开的人工智能论坛的第一场。他承诺可能在明年出台一项全面的人工智能监管法案。 <cite>Haiyun Jiang for The New York Times</cite></figcaption></figure><section><p>虽然大多无法跟上<a href="https://www.nytimes.com/2023/12/06/technology/ai-regulation-policies.html">人工智能发展</a>的脚步，世界各国的监管机构还是在采取不同的办法来监管这一技术，结果导致对人工智能的全球监管格局高度分散且混乱，这种无国界技术必将颠覆就业市场，助长虚假信息的传播，甚至可能给人类存续带来风险。</p><p>针对人工智能的主要监管框架包括：</p><p><b>欧洲基于风险制定的法规</b>：周三，<a href="https://www.nytimes.com/2023/06/14/technology/europe-ai-regulation.html">欧盟的《人工智慧法案》</a>正在进行协商，该法案将根据人工智能工具带来的<a href="https://www.nytimes.com/2021/04/16/business/artificial-intelligence-regulation.html">风险水平</a>实施相应的监管。其理念是设置一系列可变动的监管标准，旨在对风险最高的人工智能系统施加最严格的限制。该法案将根据四种情况对人工智能工具进行分类：不可接受的风险、高风险、有限风险和最低风险。</p><p>不可接受的风险包括对个人进行社会信用评分或在公共场所进行实时面部识别的人工智能系统。这类工具将被禁止。其他风险较小的工具，如生成篡改视频或“<a href="https://cn.nytimes.com/technology/20230209/artificial-intelligence-training-deepfake/zh-hat/">深伪</a>”影像的软件，则必须披露这是人工智能生成的内容。违规者将被处以相当于其全球销售额6%的罚款。风险最低的系统包括垃圾邮件过滤器和人工智能生成的电子游戏。</p><p><b>美国的自愿行为准则</b>：拜登政府为企业提供了<a href="https://www.nytimes.com/2023/07/21/us/politics/ai-regulation-biden.html">自愿监管安全风险</a>的余地。白宫在今年7月宣布，包括亚马逊、Anthropic、谷歌、Inflection、Meta、微软和OpenAI在内的多家人工智能研发企业都已同意对这些系统进行自我监管。</p><p>这些自愿监管承诺包括对工具进行第三方安全测试，即所谓的“红队检测”；对偏见及隐私问题进行研究；向政府和其他机构共享风险信息；开发能够应对气候变化等社会挑战、同时还包含识别人工智能生成素材的透明性措施的工具。各家企业已经在履行以上的许多承诺。</p><p><b>美国基于技术制定的法案</b>：任何针对人工智能的实质性监管都必须来自国会。参议院多数党领袖、纽约州民主党人查克·舒默已承诺，一项<a href="https://www.nytimes.com/2023/09/13/technology/silicon-valley-ai-washington-schumer.html">全面的人工智能法案</a>可能于明年出台。</p><p>但议员们目前已经<a href="https://www.nytimes.com/2023/09/07/technology/artificial-intelligence-framework-senate.html">提出了</a>关注人工智能系统创造和部署的法案。这些提案包括设立一个类似于食品药物管理局的机构，来监管人工智能服务供应商，审核新系统的牌照，并制定各类标准。OpenAI首席执行官萨姆·奥尔特曼对此表示支持。不过，谷歌提议让国家标准暨技术研究院作为政府监管的核心机构，该研究院成立于一个多世纪以前，没有任何监管实权。</p><p>其他法案则重点关注了人工智能系统通过吸收知识产权来创建自身系统的版权侵犯行为。有提案还讨论了选举安全和限制使用“深伪”技术的问题。</p><p><b>中国在言论监管方面行动迅速</b>：自2021年以来，中国<a rel="noopener noreferrer" target="_blank" href="https://carnegieendowment.org/2023/07/10/china-s-ai-regulations-and-how-they-get-made-pub-90117#:~:text=The%20rules%20for%20recommendation%20algorithms,placed%20on%20synthetically%20generated%20content.">迅速出台</a>了旨在监管推荐算法、深伪等合成内容和生成式人工智能的法规。这些规定包含禁止社交平台利用推荐算法设置价格歧视。人工智能开发商必须对人工智能生成的合成内容做出标记。针对如OpenAI的聊天机器人的生成式人工智能监管草案要求保证训练数据和该技术创作内容的“<a rel="noopener noreferrer" target="_blank" href="https://digichina.stanford.edu/work/how-will-chinas-generative-ai-regulations-shape-the-future-a-digichina-forum/">真实准确</a>”，许多人认为这是对人工智能系统发布内容的一种审查。</p><p><b>全球合作</b>：许多专家表示，有效的人工智能监管需要全球合作。到目前为止，在此问题上的外交努力几乎没有取得什么实质性成果。其中的一个想法是建立国际性机构，效仿为限制核武器扩张而创立的国际原子能机构。但难点在于要克服地缘政治不信任、经济竞争和民族主义浪潮，这些因素都已经与人工智能的发展紧密相连。</p></section><footer><p>Cecilia Kang驻华盛顿特区，负责报道科技和监管政策。她撰写有关科技的报道已超过20年。<a rel="nofollow" target="_blank" href="https://www.nytimes.com/by/cecilia-kang">点击查看更多关于她的信息。</a></p><p>Adam Satariano是驻欧洲的科技记者，他的报道重点是数字政策以及科技与世界事务的交叉点。<a rel="nofollow" target="_blank" href="https://www.nytimes.com/by/adam-satariano">点击查看更多关于他的信息。</a></p><p>翻译：Harry Wong</p><p><a rel="nofollow" target="_blank" href="https://www.nytimes.com/2023/12/06/technology/artificial-intelligence-regulation.html">点击查看本文英文版。</a></p></footer>
