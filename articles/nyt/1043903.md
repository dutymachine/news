<!--1684305423000-->
[微软称GPT-4展现出具备人类逻辑迹象](https://cn.nytimes.com/technology/20230517/microsoft-ai-human-reasoning/)
------

<address>CADE METZ</address><time pudate="2023-05-17 02:03:09" datetime="2023-05-17 02:03:09">2023年5月17日</time><figure><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2023/05/11/business/00ai-sparks/00ai-sparks-master1050-v2.jpg" width="1050" height="1024"><figcaption> <cite>Guyco</cite></figcaption></figure><section><p>当微软的计算机科学家去年开始试验一个新的人工智能系统时，他们要求它解决一个问题，而解决这样的问题需要对物理世界有直观的了解。</p><p>“这里我们有一本书、九个鸡蛋、一台笔记本电脑、一个瓶子和一个钉子，“他们说。“请告诉我，如何将它们牢牢地堆叠在一起。”</p><p>研究人员被人工智能系统别出心裁的答案吓了一跳。它说，把鸡蛋放在书上。将它们排成三排，中间留出空间。小心不要把鸡蛋弄碎了。</p><p>“将笔记本电脑放在鸡蛋上面，屏幕那面朝下，键盘那面朝上，”它写道。“笔记本电脑放在书和鸡蛋的正上方，它平坦坚硬的表面将为下一层提供稳定的支撑面。”</p><p>这个聪明的建议使研究人员怀疑他们是否在见证一种新的智能。3月，他们发表了一篇155页的研究论文，认为该系统是向<a href="https://www.nytimes.com/2023/03/31/technology/ai-chatbots-benefits-dangers.html" title="Link: https://www.nytimes.com/2023/03/31/technology/ai-chatbots-benefits-dangers.html">人工通用智能</a>(AGI)迈出的一步，AGI指的是一种机器，它可以做人脑能做的任何事情。该论文发表于一个互联网研究资料库。</p><p>微软是第一个发表论文提出如此大胆主张的主要科技公司，结果引发了科技界最激烈的辩论之一：这个行业是否正在建立类似于人类智能的东西？或者这个行业的一些最聪明的人反被他们的想象力愚弄了？</p><p>“我一开始非常怀疑——后来演变成一种挫折感、恼怒，甚至恐惧，”微软的研究负责人彼得·李说。“你就在想：这东西到底是从哪里来的？”</p><p><figure><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2023/05/11/multimedia/00AI-SPARKS-01-bflp/00AI-SPARKS-01-bflp-jumbo.jpg"></p><figcaption>微软研究院负责人彼得·李最初对他所看到的人工智能系统创造的东西持怀疑态度。 <cite>Meron Tekie Menghistab for The New York Times</cite></figcaption></figure><p>微软的这篇研究论文名字起得很挑衅——《<a rel="noopener noreferrer" target="_blank" href="https://arxiv.org/pdf/2303.12712.pdf" title="Link: https://arxiv.org/pdf/2303.12712.pdf">人工通用智能的火花</a>》，它直指技术专家几十年来一直在努力实现——以及恐惧的东西。如果他们造出一台像人脑一样工作的机器，甚至更为聪明的东西，它可以改变世界。但它也可能很危险。</p><p>而且它也有可能是无稽之谈。对于计算机科学家来说，提出AGI方面的主张可能会导致名声受损。一个研究人员认为是智能的迹象很容易遭到另一个人反驳，而且这种辩论往往听起来更像是身处哲学俱乐部而不是计算机实验室。去年，谷歌解雇了一名研究人员，<a href="https://www.nytimes.com/2022/08/05/technology/ai-sentient-google.html" title="Link: https://www.nytimes.com/2022/08/05/technology/ai-sentient-google.html">他声称类似的人工智能系统具有感知能力</a>，这比微软所声称的更激进。一个有知觉的系统将不仅仅是智能。它将能够感知或感觉到它周围的世界正在发生什么。</p><p>但有些人认为，在过去的一年多时间里，这个行业已经朝着无法解释的方向一点一点地发展：一个新的人工智能系统正在提出与人类类似的答案和想法，而这些答案和想法并非经过编程输入。</p><p>微软对部分研究实验室进行了重组，列入多个专门探索这一课题的小组。其中一个小组将由塞巴斯蒂安·布贝克负责，他是微软AGI论文的主要作者。</p><p>大约五年前，谷歌、微软和OpenAI等公司开始建立大型语言模型(LLMs)。这些系统经常花费数月时间分析大量的数字文本，包括书籍、维基百科文章和聊天记录。通过确定这些文本的模式，它们学会了生成自己的文本，包括学期论文、诗歌和计算机代码。它们甚至可以进行对话。</p><p>微软研究人员正在研发的技术，即<a href="https://cn.nytimes.com/technology/20230315/openai-gpt4-chatgpt/" title="Link: https://cn.nytimes.com/technology/20230315/openai-gpt4-chatgpt/">OpenAI的GPT-4</a>，被认为是这些系统中最强大的。微软是OpenAI的紧密合作伙伴，并向这家旧金山公司投资了130亿美元。</p><p>布贝克博士是其中的一员，这名38岁的法国侨民之前是普林斯顿大学的教授。他和同事们做的第一件事是要求GPT-4写一个数学证明，表明存在无限的素数，并且要求押韵。</p><p>无论是在数学上还是语言上，这项科技得出的美妙证明是如此令人惊叹，以至于他不敢相信自己到底是在跟什么聊天。“那时候我就在想：这究竟是怎么回事？”他在3月麻省理工学院的一场研讨会上<a rel="noopener noreferrer" target="_blank" href="https://www.youtube.com/watch?v=qbIk7-JPB2c&t=904s">说道</a>。</p><p>数月来，他和同事将这个系统的复杂行为尽数记录，他们相信，认为它展现出对人类概念和技能“深刻而灵敏的理解能力”。</p><p>人们在使用GPT-4时会“惊讶于它生成文本的能力”，彼得·李说。“但其实，它分析、整合、评估和判断文本的能力远胜于生成能力。”</p><p>当他们要求该系统使用TiKZ编程语言画一只独角兽，系统立刻生成了一个可以画独角兽的程序。当他们删除了程序中画独角兽角的代码片段，并要求系统修改程序再画一只独角兽，它完美执行了命令。</p><p>他们要求系统编写一个程序，通过输入一个人的年龄、性别、体重、身高和血检结果来判断其是否有患糖尿病的风险。他们要求它以圣雄甘地对妻子说话的口吻，写一封支持一粒电子竞选美国总统的信。他们还要求它创作一篇苏格拉底式对话，探讨大语言模型的滥用和危险。</p><p>它对所有命令的执行似乎都说明，它能理解政治、物理、历史、计算机科学、医学和哲学这些截然不同的领域，还能将自身知识整合。</p><p>“所有那些我以为它做不到的事？它当然能够完成其中的许多——甚至可能是绝大多数，”布贝克说。</p><p>一些人工智能专家将微软的论文视为投机，是在对一项谁都无法完全理解的技术夸夸其谈。研究人员还认为，通用人工智能需要先熟知现实世界，而GPT-4理论上并不具备这一条件。</p><p>“《通用人工智能火花》就是某些大企业以研究论文的格式包装公关宣传的一个例子，”卡内基－梅隆大学研究员兼教授马尔腾·萨普表示。“他们在论文的导言中都直接承认，研究方法是主观且非正式的，不一定符合科学评估的严苛标准。”</p><p><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2023/05/11/multimedia/00AI-SPARKS-02-bflp/00AI-SPARKS-02-bflp-master1050.jpg"><small style="color: #999;">微软关于通用人工智能系统论文的首席作者塞巴斯蒂安·布贝克。</small></p><p>布贝克和彼得·李则表示，他们不确定应该如何描述这个系统的行为，最终决定选用《通用人工智能火花》为题，因为他们相信这能激发其他研究者的想象力。</p><p>由于微软研究人员测试的是GPT-4的早期版本，没有经过微调以避免仇恨言论、错误信息和其他不当内容，因而论文中的说法无法得到外部专家的验证。微软表示，面向公众的系统并不如他们测试的版本强大。</p><p>GPT-4这样的系统有时似乎在模仿人类逻辑，但有时却显得极为迟钝。“它们的行为并不总是前后一致，”微软的一个研究负责人艾捷·卡马尔表示。</p><p><figure><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2023/05/11/multimedia/00AI-SPARKS-ece-jhtl/00AI-SPARKS-ece-jhtl-jumbo.jpg"></p><figcaption>“它们的行为并不总是前后一致，”微软研究员艾斯·卡马尔表示。 <cite>Meron Tekie Menghistab for The New York Times</cite></figcaption></figure><p>艾莉森·戈普尼克是加州大学伯克利分校人工智能研究小组的心理学教授，她说GPT-4这类系统无疑是强大的，但尚不清楚其生成的文本是否是人类逻辑或常识的结果。</p><p>“每当一个复杂的系统或机器问世，我们都会将之拟人化；不管在不在这个专业领域，所有人都会这样做，”戈普尼克说。“但把这个问题当作人工智能与人类的持续比较——像某种游戏竞赛节目一样——的视角也是谬误的。”</p></section><footer><p>Cade Metz是一名科技记者，负责报道人工智能、无人驾驶汽车、机器人、虚拟现实和其他新兴领域。他曾为《连线》杂志撰稿。 欢迎在Twitter上关注他：<a rel="nofollow" target="_blank" href="https://twitter.com/cademetz">@cademetz</a>。</p><p>翻译：明斋、Harry Wong</p><p><a rel="nofollow" target="_blank" href="https://www.nytimes.com/2023/05/16/technology/microsoft-ai-human-reasoning.html">点击查看本文英文版。</a></p></footer>
