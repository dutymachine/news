<!--1675921023000-->
[真假难辨：当“深伪”技术被用于亲中宣传](https://cn.nytimes.com/technology/20230209/artificial-intelligence-training-deepfake/)
------

<address>ADAM SATARIANO, 孟建国</address><time pudate="2023-02-09 12:59:57" datetime="2023-02-09 12:59:57">2023年2月9日</time><figure><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2023/02/01/video/01vid-deepfake-disinfo-woman-split-COVER/01vid-deepfake-disinfo-woman-split-COVER-master1050-v2.png" width="1050" height="591"><figcaption> <cite></cite></figcaption></figure><section><p>在一个视频中，一位头发梳得整整齐齐、留着胡渣的新闻主播说，他认为美国在打击枪支暴力方面缺乏行动令人汗颜。</p><p>在另一个视频中，一位女主播借由一场国际峰会宣扬中国在地缘政治关系中的作用。</p><p>但是他们看上去有些不对劲。声音生硬，无法与嘴型同步。有着电子游戏里像素化的脸，头发看起来不自然地贴在头上。字幕全是语法错误。</p><p>这两位所谓沃尔夫新闻的主播并非真人。它们是由人工智能软件创建的电脑生成形象。去年年底，一些亲中国的机器人帐户在<a href="https://www.nytimes.com/2019/11/24/technology/tech-companies-deepfakes.html">Facebook和Twitter</a>上发布了它们的视频，这是已知的第一个使用<a href="https://www.nytimes.com/2018/03/04/technology/fake-videos-deepfakes.html">深伪视频技术</a>制造虚构人物、用于国家协调的信息运动的例子。</p><p>“这是我们第一次在现实中看到这种情况，”分析虚假信息的研究公司Graphika的情报副总裁杰克·斯塔布斯说。Graphika发现了那次<a rel="noopener noreferrer" target="_blank" href="https://graphika.com/spamouflage-deepfakes/" title="Link: https://graphika.com/spamouflage-deepfakes/">亲中运动</a>，该运动似乎是为了促进中共的利益，并在英语观众面前削弱美国。</p><p>近十年来<a href="https://www.nytimes.com/2023/01/22/business/media/deepfake-regulation-difficulty.html">深伪技术</a>稳步发展，已经具备了制作会说话的数字人偶的能力。这种人工智能软件有时会被用来歪曲公众人物，例如去年在社交媒体上流传的一段冒充乌克兰总统泽连斯基<a href="https://www.nytimes.com/2022/04/05/us/politics/ukraine-russia-hackers.html">宣布投降</a>的视频。但该软件也可以凭空生造出一个人，超越好莱坞使用的传统剪辑软件和昂贵的特效工具，极大地模糊了事实与虚构之间的界限。</p><p>几乎没有法律来管理这种技术的传播，研究虚假信息的专家长期以来一直警告，深伪视频可能会进一步削弱人们在网上<a href="https://www.nytimes.com/2021/03/10/technology/ancestor-deepfake-tom-cruise.html">辨别真伪</a>的能力，并有可能遭到滥用，以此来引发动荡或制造政治丑闻。这些预测现已成为现实。</p><p>在最近发现的亲中虚假信息活动中，尽管使用的深伪技术拙劣，但它开启了信息战的新篇章。最近几周，网上还发现了另一个使用了类似人工智能技术的视频，视频里的虚构人物自称美国人，宣传对布基纳法索政府的支持，该政府因与俄罗斯的联系而受到审查。</p><p>网上可以轻松购得人工智能软件，它可以“在几分钟内制作视频，最低订阅费用每月只需几美元”，斯塔布斯说。 “这使得大规模制作内容变得更加容易。”</p><p>Graphika发现这两个虚假的沃尔夫新闻主持人与Synthesia开发的技术有关，这是一个人工智能公司，位于伦敦牛津广场的一家服装店楼上。</p><p>该初创公司已有五年历史，开发用于创建深伪形象的软件。客户只需键入剧本，然后由Synthesia工具制作的数字演员来朗读。</p><p>Synthesia表示，人工智能化身是人的“数字双胞胎”，它们基于受雇演员的外表，可以被操纵说120种语言和口音。它提供了超过85个不同性别、年龄、种族、声调和时尚风格的角色供选择。</p><p>一个人工智能角色名叫乔治，他看起来像一位经验丰富的商业主管，头发花白，穿着蓝色西装外套和衬衫。另一个叫赫利亚，戴着穆斯林头巾。还有一个形象卡洛戴着一顶安全帽。而塞缪尔则穿着医生的白大褂。（客户还可以使用Synthesia根据自己或已授予他们权限的其他人创建他们的形象。）</p><p>该公司的软件主要被客户用于人力资源和培训视频，无需精修就已足够。该软件每月只需花费30美元，可以在几分钟内制作出视频，否则可能需要几天时间，还要雇用视频制作人员和真人演员。</p><p>Synthesia在其网站上表示，整个过程“就像写封电子邮件一样简单”。</p><p><b>角色通常如何出现</b></p><p>以下是Synthesia的人工智能生成角色用于各类市场营销和相似宣传的案例。</p><p>Synthesia的联合创始人兼首席执行官维克多·里帕尔贝利表示，Graphika发现的那些用Synthesia技术创建的虚拟人物违反了其服务条款。这些条款规定，该公司的技术不应用于“政治、色情、私人、犯罪和歧视内容”。里帕尔贝利拒绝透露有关沃尔夫新闻视频幕后人员的信息，但他表示，他们的帐号已经被封停。</p><p>里帕尔贝利还表示，Synthesia有一个负责防止深伪技术被用于创造非法内容的四人团队，但他说，虚假信息和不包括直接仇恨言论、诽谤、露骨词汇和影像的内容可能很难被检测。</p><p>“非常难以确定这是否属于虚假信息，”他在观看了沃尔夫新闻的一段视频后表示。他说自己愿对“我们平台上出现的任何情况承担全部责任”，并呼吁政策制定者就如何使用人工智能工具出台<a rel="noopener noreferrer" target="_blank" href="https://www.synthesia.io/post/on-regulation">更明确的法规</a>。</p><p>里帕尔贝利说，识别虚假信息只会越来越困难。他还表示，到最后，深伪技术的复杂程度可达到“无需其他东西就能在笔记本电脑上制作一部好莱坞电影”的水平。</p><p>Graphika通过追踪沃尔夫新闻的两个虚拟人物找到了另外关于这些相同角色内容无害的网络训练视频，因而发现了Synthesia与亲中国虚假信息活动的关联。Synthesia在其网站上将这两个虚拟人物称为“安娜”和“杰森”。</p><p><b>人工智能生成的相同虚拟人物如何出现在营销和虚假信息活动中。</b></p><p>虚拟人物朗读被输入到Synthesia软件的台本。这些人物面部僵硬，声音呆板，用不了多久就能察觉出异常。</p><p>在一条支持布基纳法索新政府的视频中，安娜也有出镜。“在这场共同斗争中，让我们大家继续动员起来，支持布基纳法索的人民。”她用机械般的单调语气说道。“无祖国，毋宁死，我们终将胜利。”</p><p>深伪视频已经泛滥多年。肯德里克·拉马尔在去年的一个音乐录影带中使用了这项技术，化身为坎耶·韦斯特、威尔·史密斯和科比·布莱恩特。色情网站也因展示使用该技术非法复刻著名女演员形象的视频而受到批评。</p><p>在中国，人工智能企业对深伪工具的研发已超过五年。在2017年一场峰会的宣传演示中，中国公司科大讯飞制作了时任美国总统<a href="https://cn.nytimes.com/business/20171205/china-artificial-intelligence/">特朗普用普通话演讲</a>的深伪视频。此后，科大讯飞被美国列入了以国家安全为由限制销售美国技术的黑名单。</p><p>拥有Facebook、Instagram和WhatsApp的Meta宣称，在《纽约时报》联系后，该公司删除了至少一个与亲中深伪视频有关的帐号。该公司拒绝进一步置评，称不会允许以误导公众为目的操纵视频和其他媒体内容。Twitter没有回应评论请求。</p><p>Graphika表示，该公司是在追踪与亲中虚假信息活动“spamouflage”相关的社交媒体帐号时发现这些深伪视频的。在这些活动中，政治垃圾邮件帐号会在网上发布内容，然后利用同一网络的其他帐号在各个平台传播这些素材。</p><p>研究人员说，比起这些观看人数并不多的视频造成的实际影响，深伪技术在这些视频的运用更值得关注。Graphika表示，11月22日至11月30日期间，包含这些所谓沃尔夫新闻主播的两段视频被五个帐号发布了至少五次。这些帖子随后被至少另外两个帐号转发，这些帐号似乎同属于一个亲中帐号网络。</p><p>斯塔布斯表示，虚假信息散布者会继续尝试人工智能软件，制作出越来越逼真的媒体内容，难以被识别与核实。</p><p>“我们今天看到的情况就是未来的另一个预兆，”他说。</p></section><footer><p>Elian Peltier自达喀尔塞内加尔对本文有报道贡献。本文视频由Axel Boada制作。</p><p>Adam Satariano是驻欧洲的科技记者，他的工作重点是数字政策以及技术与国际事务的交叉点。 欢迎在Twitter上关注他：<a rel="nofollow" target="_blank" href="https://twitter.com/satariano">@satariano</a>。</p><p>孟建国(Paul Mozur)是时报科技记者。他所在的团队因报道冠状病毒大流行而获得2021年普利策公共服务奖。欢迎在Twitter上关注他： <a rel="nofollow" target="_blank" href="https://twitter.com/paulmozur">@paulmozur</a>。</p><p>翻译：Harry Wong、明斋</p><p><a rel="nofollow" target="_blank" href="https://www.nytimes.com/2023/02/07/technology/artificial-intelligence-training-deepfake.html">点击查看本文英文版。</a></p></footer>
