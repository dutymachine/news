<!--1655174221000-->
[谷歌工程师称AI“有意识、有灵魂”，遭公司停职](https://cn.nytimes.com/technology/20220614/google-chatbot-ai-blake-lemoine/)
------

<address>NICO GRANT, CADE METZ</address><time pudate="2022-06-14 10:20:07" datetime="2022-06-14 10:20:07">2022年6月14日</time><figure><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2022/06/12/business/12google-ai1/12google-ai1-master1050.jpg" width="1050" height="700"><figcaption>一些人工智能研究者已乐观地声称，这种技术很快会达到有知觉力的水平，但许多人立即反驳了这些说法。 <cite>Laura Morton for The New York Times</cite></figcaption></figure><section><p>旧金山——最近，谷歌驳回了一名工程师关于该公司的人工智能（简称AI）有知觉力的说法，然后让其带薪休假，这一事件再次显露出围绕着谷歌最先进技术的争论。</p><p>布雷克·勒穆瓦纳是谷歌“负责任的AI技术”(Responsible A.I.)部门高级软件工程师，他在接受采访时表示，他已于周一开始休假。公司人力资源部称他违反了谷歌的保密政策。勒穆瓦纳说，他在被停职的前一天把一些文件交给了一名美国参议员的办公室，他说这些文件提供了谷歌及其技术有宗教歧视的证据。</p><p>谷歌表示，公司的AI系统模仿人们的对话交流，能对不同的话题进行复述，但没有意识。“我们的团队——包括伦理学家和技术专家——已根据我们的AI原则对布莱克的担忧进行了核查，并告知他，证据不支持他的说法，”谷歌发言人布莱恩·加布里埃尔在一份声明中说。“在更广泛的人工智能界，有些人正在仔细考虑有知觉力AI或通用AI的长远可能性，但是，通过将目前建立在对话模型上的AI拟人化来实现这种可能性是讲不通的，因为这些模型没有知觉。”《华盛顿邮报》首先<a rel="noopener noreferrer" target="_blank" href="https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/">报道</a>了勒穆瓦纳暂被停职的消息。</p><p>几个月来，勒穆瓦纳一直与谷歌的经理、高管和人力资源部门争吵，因为他令人吃惊地声称，谷歌的对话应用语言模型（简称LaMDA）有意识，有灵魂。谷歌表示，公司的数百名研究员和工程师与内部使用的LaMDA工具进行对话后，得出了与勒穆瓦纳不同的结论。大多数人工智能专家认为，该行业距离计算机知觉还有很长的路要走。</p><p>一些AI研究者很早以前就已乐观地声称，人工智能技术很快会达到有知觉力的水平，但许多人立即反驳了这些说法。“如果你用过这些系统，你永远也不会说这种话，”在加州大学伯克利分校和加州大学旧金山分校任职的研究员伊马德·赫瓦贾说道，他正在探索类似的技术。</p><p>在争当人工智能先锋的同时，谷歌的研究部门也在过去几年里陷入了丑闻与争议。该部门的科学家和其他员工经常在技术和人事问题上争吵不休，这些争吵有时会进入公众领域。今年3月，谷歌<a href="https://www.nytimes.com/2022/05/02/technology/google-fires-ai-researchers.html">解雇了</a>一名研究员，因为此人曾试图对两名同事已发表的研究结果公开表示不同意。在批评了谷歌的语言模型后，两名研究AI伦理的研究员——蒂姆尼特·加布鲁和玛格丽特·米切尔<a href="https://www.nytimes.com/2021/02/19/technology/google-ethical-artificial-intelligence-team.html">被解雇</a>，让该部门进一步蒙上阴影。</p><p><img src="https://images.weserv.nl/?url=static01.nyt.com/images/2022/06/12/business/12google-ai2/12google-ai2-master1050.jpg"><small style="color: #999;">2005年的布莱克·莱穆安，当时他是美国陆军的一名特种兵。</small></p><p>勒穆瓦纳是一名退伍军人，他把自己描述为一名牧师，曾是服刑囚犯，也是一名AI研究员。勒穆瓦纳对谷歌的高管们（最高是负责全球事务的总裁肯特·沃克）说，他认为LaMDA是一个七八岁的孩子。他希望公司在对计算机程序进行实验前征得其同意。他的宣称是建立在其宗教信仰基础上的，他认为公司的人力资源部门对他的宗教信仰有歧视。</p><p>“他们一再怀疑我是否神志正常，”勒穆瓦纳说。“他们说，‘你最近看过精神科医生吗？’”公司在安排他带薪休假前的几个月里，曾建议他请心理健康假。</p><p>Meta的人工智能研究主管、在神经网络兴起中起关键作用的扬恩·莱坎本周在接受采访时说，这类系统还没有强大到足以获得真正智能的程度。</p><p>谷歌的这项技术被科学家称为<a href="https://www.nytimes.com/2018/03/06/technology/google-artificial-intelligence.html">神经网络</a>，是一个通过分析大量数据来学习技能的数学模型。例如，通过确定几千张猫照片中的模式，它可以学会识别猫。</p><p>在过去几年里，谷歌和其他领先公司已设计了<a href="https://www.nytimes.com/2020/11/24/science/artificial-intelligence-ai-gpt3.html">从数量巨大的文章中学习的神经网络</a>，它们用的数据包括未出版的书籍和维基百科上成千上万篇文章。这些“大型语言模型”能用在许多任务上。它们能对文章进行总结、回答问题、生成推文，甚至能写博客文章。</p><p>但它们也存在巨大的缺陷。它们有时能写出完美的散文，有时却生成毫无意义的话。这些系统非常擅长将它们以前遇到过的模式再现出来，但不能像人类那样思考。</p></section><footer><p>Nico Grant是一名在旧金山报道谷歌新闻的记者。他此前在彭博新闻社任职五年，关注谷歌和云计算方面的新闻。欢迎在Twitter上关注他：<a rel="nofollow" target="_blank" href="https://twitter.com/nicoagrant">@nicoagrant</a>。</p><p>Cade Metz是一名科技记者，负责报道人工智能、无人驾驶汽车、机器人、虚拟现实和其他新兴领域。他曾为《连线》杂志工作。欢迎在Twitter上关注他 <a rel="nofollow" target="_blank" href="https://twitter.com/cademetz?lang=en">@CadeMetz</a>。</p><p>翻译：Cindy Hao</p><p><a rel="nofollow" target="_blank" href="https://www.nytimes.com/2022/06/12/technology/google-chatbot-ai-blake-lemoine.html">点击查看本文英文版。</a></p></footer>
