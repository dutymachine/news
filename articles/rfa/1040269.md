<!--1677173640000-->
[专访AI专家杜奕瑾：当审查大国遇上 “有问必答”的ChatGPT](https://www.rfa.org/mandarin/yataibaodao/kejiaowen/jt-02172023110204.html)
------

<p><a href="https://www.cna.com.tw/news/acn/202302170127.aspx"></a>近日，美国科技公司OpenAI开发的聊天机器人ChatGPT引发中国科技界关注。但随后有消息显示，中国官方要求迅速对此整改，研发中的“中国版ChatGPT”如未经网信办评估也“不得上线”。本台记者唐家婕就此专访了台湾AI实验室创始人、美国微软公司原人工智能团队（AI.R.）的亚太研发总监杜奕瑾，请他就当前ChatGPT在中国的发展状况发表了看法。</p><p><span class="result-title"> </span></p><ul><li><strong><span class="result-title"> <a class="state-published" href="https://www.rfa.org/mandarin/Xinwen/8-02102023140322.html">警告ChatGPT概念股风险 汉王科技被深交所重点监控</a> </span></strong></li><li><span class="result-title"> <a class="state-published" href="https://www.rfa.org/mandarin/yataibaodao/kejiaowen/vs-02082023123205.html"><strong>ChatGPT正夯 中国人工智能研究优势与局限何在？</strong></a> </span></li><li><span class="result-title"><a class="state-published" href="https://www.rfa.org/mandarin/Xinwen/10-01312023152219.html"><strong>百度可能发布中国版ChatGPT 一样受审查！</strong></a></span></li></ul><p><span class="result-title"> </span></p><p><strong>ChatGPT在中国“说错话”？</strong></p><p>在中国，"说错话”的人可能会被删帖封号，甚至被当局以“寻衅滋事”罪找麻烦；但如果“说错话”的是机器人呢?</p><p>美国科技公司OpenAI开发的聊天机器人ChatGPT大火，这是一款可以向人一样自然对话的语言机器人，它还可以借由用户的反馈做出不同的回应并持续学习。</p><p>中国网友迫不及待地透过VPN使用ChatGPT，探索各种在中国被防火墙屏蔽的“禁忌话题”。21日传出，中国官方出手要求迅速整改下线ChatGPT代理服务，且研发中的“中国版ChatGPT”未经网信办评估“不得上线”。</p><p>ChatGPT到底是什么跨时代的AI发明？当言论审查大国遇上会聊天、会学习的对话机人时，ChatGPT 在中国会产生什么变形？中美在AI领域的竞争朝什么方向前进?决战点又在哪里呢?大概没有谁比台湾AI实验室创始人杜奕瑾(Ethan Tu)更适合解答这些疑问。</p><p>现年47岁的杜奕瑾在台湾高雄长大，大二时在台大宿舍里架设了BBS站PTT，PTT长成台湾最具影响力的线上论坛。杜奕瑾的科技探索之路没有就此停歇，他参与了台湾第一个入口网站蕃薯藤搜寻引擎的建立，随后到美国国家卫生研究院(NIH)从事基因序列相关检测研究。</p><p>2006年至2017年，杜奕瑾加入美国微软公司进行搜寻引擎 bing 的开发，以及担负起微软人工智能的研究工作，成为微软人工智能团队（AI.R.）首席亚太区研发总监。他见证了北京微软研究院培育出一批批中国人工智能人才的年代，也在第一线看到美中人工智能发展的不同路径。</p><p>2017年，杜奕瑾离开微软返台创立非政府、非营利导向的台湾人工智能实验室(Taiwan AI Labs)</p><p><strong>中国能复制出ChatGPT吗?</strong></p><p>记者:Ethan你好，谢谢你接受自由亚洲电台的访问。ChatGPT从去年11月30日推出， 到现在快三个月。在你看来，ChatGPT会造成轰动的原因是什么？帮我们科普一下，它在AI发展又有什么重要的意义？</p><p>杜奕瑾: ChatGPT 是一个突破性的Conversational AI(对话人工智能)，它可以依照使用者的问题很自然流畅地回答， 而且它是可以引经据点，讲得头头是道。再来，因为它的文本量很多， 它的语言模组(language model)够复杂，所以其实你可以跟它有各种的互动。</p><p>你可以请它假装用某个人的口吻去回答你，可以让它写程式、写歌、产生诗词， 甚至它的对话里有contextual (上下文语境)，就是你可以借由之前跟它讲的对话 ，与它之后的回答有先后文的关系。这个在过去来讲，是模型对话的很大的突破。</p><p>记者:现在ChatGPT大热，百度、阿里巴巴，甚至许多中国科技公司都誓言要推出相关的产品。北京政府上周刚发布的《人工智能产业发展白皮书》也写明，要“支持头部企业打造对标ChatGPT的大模型”，无条件开放超过15000个公部门的数据集供AI培训。在你看来，中国复制得了ChatGPT吗?</p><p><span class="result-title"> </span></p><p><figure class="image-richtext image-inline captioned" style="width:832px;"><img alt="北京政府2月14日发布《人工智能产业发展白皮书》，写明要“支持头部企业打造对标ChatGPT的大模型”。（北京政府网站）" height="673" src="https://www.rfa.org/mandarin/yataibaodao/kejiaowen/jt-02172023110204.html/2.jpg/@@images/96110fdd-57ac-42fe-8bbe-2714aa49f020.jpeg" title="2.jpg" width="832"/><figcaption class="image-caption">北京政府2月14日发布《人工智能产业发展白皮书》，写明要“支持头部企业打造对标ChatGPT的大模型”。（北京政府网站）</figcaption><small></small><div id="zoomattribute"><a data-caption="北京政府2月14日发布《人工智能产业发展白皮书》，写明要“支持头部企业打造对标ChatGPT的大模型”。（北京政府网站）" data-fancybox="" href="https://www.rfa.org/mandarin/yataibaodao/kejiaowen/jt-02172023110204.html/2.jpg" id="single_image" title="北京政府2月14日发布《人工智能产业发展白皮书》，写明要“支持头部企业打造对标ChatGPT的大模型”。（北京政府网站）"><img src="/++plone++rfa-resources/img/icon-zoom.png"/></a></div></figure></p><p>杜奕瑾:这种语言模型生成(技术)现在不是一个什么交易秘密， 因为它的Instruct GPT(编按:ChatGDPT的前身，在2022年一月释出)的技术让大家可以知道是怎么运作的。再来谈到中国的资料文本量，AI训练要非常多的文本量 ，因为大家都做过搜寻引擎， 要这么多的文本量其实不是那么的复杂。</p><p>我觉得比较特别的是，如果要去训练出这个自然对话模型，有几个关键因素:</p><p>第一，我觉得在美国这个地方去训练 ChatGPT模型因为它的内容流动比较自由， 我们在内容多元性来说，可以拿到比较多元的资讯。</p><p>另外，它(语言机器人)产生的结果在相对自由的地区 ，不会影响到你的这家公司的发展。但是在言论比较紧缩的地方， 由于ChatGPT可能可以产生各种不预期的内容。其实相对来讲，它去发展语言模型的风险会比较高。</p><p>如果说要讲资料量的多寡或者中国人或美国人的聪明度， 我相信都是差不多。但是你如果说是有差别的，可能就是在制度面的这部分。</p><p><strong>当审查大国遇上 “有问必答”的语言机器人</strong></p><p>记者:当AI机器人回答出对中国当局来说“敏感”的答案，App就被封、公司被处罚了。在你看来，中国互联网的审核，对发展中国版的ChatGPT有什么影响呢? 相较于美国的ChatGPT从谷歌、推特、Reddit上去收集文本，中国从百度、微博上去收集文本，会训练出什么样的语言机器人呢?</p><p>杜奕瑾:第一，应该说你在这个内容是受到限制的市场，拿到的文本也已经是受到限制的内容，也就是说有些资料是没有在这里面的。所以你相对来讲，(AI训练)得到的结果也不会那么的完整。</p><p>第二，语言生成模型也是可以生成不在原本文本训练的内容规范里面。 你可以借由一些 contextual(上下文)的输入，去注入你想要的结果，它甚至有可能产生你本来不预期的结果。</p><p>我之前在微软原本负责对话机器人，我负责微软Cortana，也包含中国市场。在美国，我们曾推出一个“Tay”对话机器人(ChatBOT)，这个对话机器人因为产生种族歧视、 仇恨相关的言论， 我们在不到一天的时间在美国市场下架。相较于在美国市场， 你(公司)可能只是面对道德上面的攻击；但在中国市场，你有可能会因为这个对话引擎讲一些“不恰当”的话， 造成你的组织、 你的这整个系统在这个市场被封闭 。</p><p>其实在这段时间， 一些中国山寨的ChatGPT， 它只是在中国加一个服务， 然后再透过美国的ChatGDP 得到答案之后，再送回中国。像这种山寨ChatGPT在中国很多很快就被封闭的其中一个原因，就是因为它会产生一个不可预期的回答，这对提供服务的组织来讲是有风险的。</p><p>记者:但反过来讲，有没有可能训练出一个符合威权政府、独裁政府需要的对话机器人呢?</p><p>杜奕瑾:不排除是有可能。在发展出网路的时代，大家原本觉得网路可以自由的表达，但因为在威权国家会以限缩网域名称、关键字，管制关键字的方式去限缩相关言论。</p><p>但是这种语言生成式模型，封闭这些关键敏感的言论会比过去的更难。因为它其实是可以绕著说，还是可以把一些“不恰当”的内容说出来。</p><p><span class="result-title"> </span></p><p><figure class="image-richtext image-inline captioned" style="width:1280px;"><img alt="ChatGPT标志（路透社）" height="853" src="https://www.rfa.org/mandarin/yataibaodao/kejiaowen/jt-02172023110204.html/2023-02-13t120053z_261134784_rc2k7z97d0ap_rtrmadp_3_openai-chatgpt-regulation.jpg/@@images/49a26a8f-f2ba-4086-9ce7-eace6be3c923.jpeg" title="2023-02-13T120053Z_261134784_RC2K7Z97D0AP_RTRMADP_3_OPENAI-CHATGPT-REGULATION.JPG" width="1280"/><figcaption class="image-caption">ChatGPT标志（路透社）</figcaption><small></small><div id="zoomattribute"><a data-caption="ChatGPT标志（路透社）" data-fancybox="" href="https://www.rfa.org/mandarin/yataibaodao/kejiaowen/jt-02172023110204.html/2023-02-13t120053z_261134784_rc2k7z97d0ap_rtrmadp_3_openai-chatgpt-regulation.jpg" id="single_image" title="ChatGPT标志（路透社）"><img src="/++plone++rfa-resources/img/icon-zoom.png"/></a></div></figure></p><p><strong>ChatGPT: 进化版的键盘侠?</strong></p><p>记者:什么叫做绕著说出来?有什么例子吗?</p><p>杜奕瑾:比如说，在美国市场也有一些比较敏感的内容，你不能在ChatGPT里面去讲到违反一些法令，像是推荐药品、医疗等内容。但是你还是可以换个话去说(问机器人)， 然后它(对话机器人)有可能讲得出一些可能会违法律规范的内容。</p><p>记者:也就是说，这是一个会学习的语言机器人，它可能像是进化版的键盘侠，比现有的审查工具更厉害了?<br/>杜奕瑾:对，所以其实现在也有一些评论家讨论ChatGPT最危险的就是:它可能会一本正经的胡说八道。 在自由的国家或许大家知道它在胡说八道是无所谓， 但是在有些地方你说错话，是会有严重的后果 ，甚至是违反当地的法规。</p><p>同理，在有些地方，大家会比较不敢去做生成式模型的发展，就因为它的相对的、你需要做到的审查的规格就是更高。</p><p><strong>ChatGPT会成为散布假消息的帮凶吗?</strong></p><p>记者:中国官宣已经出来指责ChatGPT在涉疆问题上和美政府口径一致，说ChatGPT“在西方的宣传活动带有重要角色”。你会怎么看这样对Open AI的指控？</p><p>杜奕瑾:人工智能在训练的时候， 其实它文本的内容会一定程度的影响到它生成模型之后， 生成内容的倾向。如果它的文本内容原本就是在以美国市场为主的文本内容来讲话，训练出来当然就是倾向这个市场原本有的文本内容。 <br/>我觉得，这可能不是一个特别去选择的结果，而是因为它训练的来源主要是在OpenAI这边的样本。</p><p>记者:反过来说，中国政府生成语言机器人，传授的就是中国视角的论述模式?</p><p>杜奕瑾:其实甚至不需要训练，只要用ChatGPT的语言模型拿来做应用，就可以影响它去有中国视角的结果。以中国现在的能力，要去训练一个ChatGPT运用在自由市场，我相信这个能力绝对是有的。</p><p>记者:这听起来可以被滥用成假消息、宣传的工具?</p><p>杜奕瑾:所以现在已经开始有很多科技伦理的议题，如果这种大型语言模型是未来会被广泛应用的话，当然会被应用在好的地方，帮人类做很多事情， 写程式、 创作、总结文本。但它也能是你一个助理写手， 你可以用它换个口吻写成一个负面的、虚假的报导。</p><p>如果说这个能力被滥用的话，它也有可能被用来作为这种假消息传送的工具；而相对应的假消息防御的组织会更难去抵御，因为它是可以很容易大量地依照不同的新闻来源去生成类似、但是虚假的内容。</p><p><strong>中美AI大比拼</strong></p><p>记者:现在谈中国跟美国的人工智能竞争时，我们常听到中国AI的研究已经领先了，甚至学术论文已经超越美国。你在美中产业界几十年，观察到的是这样的趋势吗?</p><p>杜奕瑾:中国训练起来的学生有一个习惯， 当我们使用哪个KPI作为指标的时候，中国一定可以做到领先指标。所以，当领先指标用在模型研发上，变成美国做了一个样本，中国就一定会比它更多。</p><p>但领先指标代表的意义是什么，不见得是可以有更好的结果。就像大家会思考，为什么人工智能的领域有很多突破性应用都是从美国开发之后，中国才开始去复制，或者去做到更进一步？有一个原因就是，中国太重视指标，以至于它在指标各项去做领先的时候，其实在创新突破上反而是欠缺的。</p><p><span class="result-title"> </span></p><p><figure class="image-richtext image-inline captioned" style="width:1280px;"><img alt="ChatGPT是OpenAI公司开发的人工智能聊天程式。（法新社图片）" height="853" src="https://www.rfa.org/mandarin/yataibaodao/kejiaowen/jt-02172023110204.html/000_337p9f8.jpg/@@images/45e778ae-b7ad-4b70-93a2-c2a1e25c45fc.jpeg" title="000_337P9F8.jpg" width="1280"/><figcaption class="image-caption">ChatGPT是OpenAI公司开发的人工智能聊天程式。（法新社图片）</figcaption><small></small><div id="zoomattribute"><a data-caption="ChatGPT是OpenAI公司开发的人工智能聊天程式。（法新社图片）" data-fancybox="" href="https://www.rfa.org/mandarin/yataibaodao/kejiaowen/jt-02172023110204.html/000_337p9f8.jpg" id="single_image" title="ChatGPT是OpenAI公司开发的人工智能聊天程式。（法新社图片）"><img src="/++plone++rfa-resources/img/icon-zoom.png"/></a></div></figure></p><p>中国有非常优秀的学生，但为什么在中国发表这么多论文之后，比较突破性的发展还是从美国这边发生？其实不是竞争力的关系，而是环境以及人思考的方式去造就不同发展的方向。这些不同发展方向，不见得是从我们传统这些指标 可以决定哪边比较优秀的。</p><p>记者: 那么，美中AI发展的方向有什么不同?</p><p>杜奕瑾:就我过去的经验，在美国发展人工智能的领域比较是属于就是由下而上。比如说BigTech(科技公司引领)这种模式，以人为本，出发点是当我们在思考未来人类有什么需要，做出各种不同的尝试。</p><p>中国会比较是属于Big Government(大政府引领)的这种模式，就是当我们看到比如美国的什么领先指标， 我们就大家齐心齐力共同去做一个比它更好、更强、更厉害的相关的生成模型。所以我觉得，中美发展的驱动力不同、 环境不同；还有像我们刚才讲，在比较自由的市场跟比较紧缩的市场，会导致你(开发者)选择的题目也会不一样， 以至于你可以看到它落地的应用的范围也会不一样。</p><p>记者:这我就想到美国公司做出了创新的IOS系统，中国公司在这之上去长出了Wechat、Tiktok；美国公司特斯拉释出了自动驾驶技术开源代码，过去几年，中国科技公司往这个领域投资说要弯道超车。那一个关键的AI战场会在哪个领域呢?会是ChatGPT吗?</p><p>杜奕瑾: 在软体以及人工智能的这个世界有一个很重要，当你有一个领先指标出现的时候， 除非你做一个市场区隔，就像Google出现的时候 你再做一个great firewall，因为中国市场基本上也够大， 那中国就会发展出自己特色的人工智能或软体工业。</p><p>但是如果说这个市场区隔没有做出来的话， 因为通常跑在前面的，不管是软体或是人工智能引擎，它会一定程度累积到更多的使用者、搜集到更多的资料， 所以其实你如果是想纯粹去用复制的方式去做到一个生成式模型，其实是很难去超越现在ChatGPT已经做到的成果。</p><p>美国市场其实有一个优势，相对来讲比较多元 、比较自由， 所以即使是这类高端人才的人数不见得比中国多，但在这种环境之下，它孕育出来的成果就是会比较多，而不是从既有架构去做复制，因此突破性的发展在这种市场是比较容易发生的。</p><p>记者: 你怎么评估芯片出口限制对中国发展AI的影响呢?</p><p>杜奕瑾:对，我想如果说只是用来作为训练ChatGPT，未来的这种大型的语言模型一定需要很大的运算能力，你拥有越多有运算能力的组织，训练这个大型的语言模型就会越有效率。</p><p>我相信，中国现有的算力应该是足够让中国去做训练的，但当你要把它用来大量广泛的使用，以及把人工智能的算法变成在每个地方都可以使用，这就需要更多AI芯片设备。相对来讲，(缺少芯片)你的未来的发展可能就会受到限制。</p><p><strong>人工智能未来的决战点：确保人权、隐私</strong></p><p>记者:你参与微软在美国、中国的人工智能发展几十年后决定回到台湾创立AI实验室，你为什么看好台湾在AI领域的发展?</p><p>杜奕瑾:台湾的言论新闻自由、经济自由，造就的土壤让这边的人也能非常多元、有创新能力。当我们在讲一个人工智能领域的发展，你需要有多元的内容以及文化，台湾是在亚太区域很有代表性。</p><p><span class="result-title"> </span></p><p><figure class="image-richtext image-inline captioned" style="width:1280px;"><img alt="杜奕瑾认为，人工智能未来的决战点在确保人权隐私保障。（Taiwan AI Labs 提供）" height="852" src="https://www.rfa.org/mandarin/yataibaodao/kejiaowen/jt-02172023110204.html/3.jpg/@@images/47fccee0-5cde-4589-a0a0-af9e7e79e6d4.jpeg" title="3.JPG" width="1280"/><figcaption class="image-caption">杜奕瑾认为，人工智能未来的决战点在确保人权隐私保障。（Taiwan AI Labs 提供）</figcaption><small></small><div id="zoomattribute"><a data-caption="杜奕瑾认为，人工智能未来的决战点在确保人权隐私保障。（Taiwan AI Labs 提供）" data-fancybox="" href="https://www.rfa.org/mandarin/yataibaodao/kejiaowen/jt-02172023110204.html/3.jpg" id="single_image" title="杜奕瑾认为，人工智能未来的决战点在确保人权隐私保障。（Taiwan AI Labs 提供）"><img src="/++plone++rfa-resources/img/icon-zoom.png"/></a></div></figure></p><p><figure class="image-richtext image-inline captioned" style="width:1915px;"><img alt='2月21日传出，ChatGPT中国代理服务遭当局要求"整改下线" (网路截图)' height="685" src="https://www.rfa.org/mandarin/yataibaodao/kejiaowen/jt-02172023110204.html/4.jpg/@@images/2fd99c4f-7fc9-4082-ab7a-5958ac9b2c91.jpeg" title="4.jpg" width="1915"/><figcaption class="image-caption">2月21日传出，ChatGPT中国代理服务遭当局要求"整改下线" (网路截图)</figcaption><small></small><div id="zoomattribute"><a data-caption='2月21日传出，ChatGPT中国代理服务遭当局要求"整改下线" (网路截图)' data-fancybox="" href="https://www.rfa.org/mandarin/yataibaodao/kejiaowen/jt-02172023110204.html/4.jpg" id="single_image" title='2月21日传出，ChatGPT中国代理服务遭当局要求"整改下线" (网路截图)'><img src="/++plone++rfa-resources/img/icon-zoom.png"/></a></div></figure></p><p>另外一方面，台湾自己本身人工智能的运算的能力 、人工智能相关的芯片以及相关的硬体设备在全球都是领先地位。在台湾做人工智能的发展，从想法到应用落地有非常大的竞争优势。再来就是台湾在这段时间，公司部门其实都有一个有共识的共同目标，用人工智能带起软体、硬体整个产业链。</p><p>台湾我觉得最大的优势就是我们是一个可信赖的合作伙伴， 我们跟全世界去做各种人工智能相关的研发， 讲究的是code of ethics( 道德准则)。我们有一套从算法的研发验证到确效的非常严谨的流程，它是保障人权隐私、确保不会有偏见，以及保障这个结果及流程是可以被验证的， 这是被世界非常认同的。</p><p>以这个角度来讲，过去大家会觉得人工智能的决战点在哪里，资料量是一个、你的软体的能力是一个、运算能力是一个，那另一个就是我们是不是可信任的solution provider(解决方案提供商)。</p><p>记者:能不能谈比较具体的例子让我们的读者了解，比如台湾防疫数据的搜集及应用与中国健康码的差别在哪里?</p><p>杜奕瑾:我想，大家都有注意到台湾的大法官释宪案。在台湾，对资料的人权的保障是非常的强大的， 台湾政府在收集个人资料非常小心，也必须确保人权隐私。</p><p>在台湾，社交距离APP以及台湾人工智能实验室做科技反应相关的发展， 我们第一件事情就是利用Rights-Respecting Technology(尊重人权隐私的科技) ， 就是我们尊重数据，不把你的数据带离你的个人装置，中央政府并没有一个中央的资料库去搜集你的数据。</p><p>台湾人工智能实验室是第一个倡议联邦式学习分析的机构，尊重资料所有权，也就是资料拥有者有权管理资料。这种做法比较符合欧盟的GDPR（通用资料保护规则）。这种去中心化、保障人群隐私的算法科技，其实才是未来可信任人工智能研究的一个基础。</p><p>记者:谢谢你接受我的访问。</p><p>杜奕瑾:谢谢你。</p><p><span class="result-title"> </span></p><p>记者:唐家婕    责编: 何平    网编: 瑞哲</p><p><span class="result-title"></span></p>
