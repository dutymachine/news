<!--1686586504000-->
[人工智能：人类准备好了吗？ - 特别节目](https://www.rfi.fr/cn/%E4%B8%93%E6%A0%8F%E6%A3%80%E7%B4%A2/%E7%89%B9%E5%88%AB%E8%8A%82%E7%9B%AE/20230612-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-%E4%BA%BA%E7%B1%BB%E5%87%86%E5%A4%87%E5%A5%BD%E4%BA%86%E5%90%97)
------

<div>12/06/2023 - 16:51</div><img src="https://s.rfi.fr/media/display/b6ce4ae2-d94d-11ed-8642-005056a90284/w:1280/p:16x9/AP19135381076587.jpg"><p><strong>人工智能不再是神话，它早已融入人们的日常生活，对未来的诸多思考把人工智能的利弊推向全球全民大讨论的前沿。而随着ChatGPT跃居有史以来成长最快的机器人程序，公众的焦虑情绪开始蔓延。                    </strong></p><div><p>中国网络热传的一份视频显示，今年春天，江苏徐州一家医院的大厅当中，一名女子不知为何手持棍棒，愤怒地砸向医院的迎宾人工智能机器人。智能机器人在女子的棍棒击打下零件散落一地，一旁的前台接待人员见状纷纷躲避。女子看上去情绪崩溃，一边用手指着智能机器人，一边向它大吼，控诉着什么。虽无法确定这一事件的起因，人们仍戏称该女子“打响了人类与人工智能的第一仗”。根据一些说法，这名女子因为家人住院哭得很伤心，人工智能机器人看到后，赶来安慰这名女子，问她想不想要听笑话，这一不合时宜的安抚引发了女子不可遏制的怒火。不少给视频留言的人们在看热闹之余，也指出“这就是为什么人工智能永远无法代替人类，因为机器没有情感，就算有，也是人类赋予的，需要人类的程序设定”；“看到有人在哭，智能机器人就会上前去安慰，但它所拥有的智慧，暂时并不能对哭泣的人类为何哭泣进行更加具体的判断，从而进一步做出与该场景相符的行动”。然而，智能机器人在情感上会始终逊于，或者依赖人类对其的训练吗？</p><p>同样在不久前，北京一家科技公司推出了一款可以解异地恋情侣相思之苦的“智能神器”，主打智能远程传输真人的亲吻力度、方式、甚至体温与声音，为人们提供仿生的交互式亲密接触。使用者需要下载应用程序，与另一方进行匹配，之后便可通过各自手持的硅胶配件，来感受另一方实时的亲吻。这一智能“神器”的使用者并非仅限情侣，陌生人也可以在社交广场上进行随机配对，向聊得投机的陌生人发出亲吻邀请。此事在中国各社交平台引发热议，热度之大，也被路透社所报道，同时引发了人们对于道德和个人生物数据隐私的思考。</p><p>生物数据隐私泄露问题已经在现实生活中引发过令人惊叹的案件。今年春天，中国包头市警方公布了一起人工智能诈骗案：诈骗案的受害人是一位福州的科技公司法人代表，被一位朋友要求转账430万人民币。由于已经通过微信视频核对过这位朋友的身份，他便照做。事后通过电话联系，才发现受骗。诈骗人员正是使用了换脸与拟声的智能科技，才让微信视频另一端的受害者打消了疑虑。</p><p>面对人类与人工智能接触的激增，与这一接触的激增所引发的诸多问题，多国政府已着手采取行动。在美国，路透社-益普索近期的民意调查显示，接受调查的大多数美国人认为，人工智能技术的迅速发展可能危及人类的未来；超过三分之二的受访美国人担心人工智能的负面影响；61%的受访美国民众认为人工智能可能会威胁到人类文明。</p>    <div data-media-video-WBMZ89757-RFI-CN-20230609 data-wrapper-video-player data-show-hidden-video-player="WBMZ89757-RFI-CN-20230609"><divdata-hidden-video-player="WBMZ89757-RFI-CN-20230609"><video-playermedia-id="WBMZ89757-RFI-CN-20230609"video-type="youtube"source="https://www.youtube.com/embed/2btsLrhTJvk"locale="zh-CN"type="main"video-id="2btsLrhTJvk"playlist=""live=""embed_config = "{&quot;primaryThemeColor&quot;:&quot;#e2001a&quot;}"playsinline="1"autoplay    title=""                @ready="onPlayerReady"@play="onPlayerPlay"@ad_playing="onPlayerAdPlay"@ad_ending="onPlayerAdEnd"@paused="onPlayerPaused"@ended="onPlayerEnded"@cued="onPlayerVideoCued"@buffering="onPlayerBuffering"@destroyed="onPlayerDestroyed"><div><div></div></div></video-player></div><figure><div><picture><sourcetype="image/webp"srcset="https://s.rfi.fr/media/display/ecda34ea-00a1-11ee-95ba-005056bf30b7/w:246/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%3A%20&quot;,&quot;hash&quot;:&quot;87def98eaa9ac99bf1437b8584c9fc7c372eaaca18e031e0d559056e0167658c&quot;,&quot;title&quot;:&quot;%E5%A4%A7%E4%BC%97%E7%9A%84%E5%BF%A7%E8%99%91&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1638.webp 246w,https://s.rfi.fr/media/display/ecda34ea-00a1-11ee-95ba-005056bf30b7/w:388/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%3A%20&quot;,&quot;hash&quot;:&quot;87def98eaa9ac99bf1437b8584c9fc7c372eaaca18e031e0d559056e0167658c&quot;,&quot;title&quot;:&quot;%E5%A4%A7%E4%BC%97%E7%9A%84%E5%BF%A7%E8%99%91&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1638.webp 388w,https://s.rfi.fr/media/display/ecda34ea-00a1-11ee-95ba-005056bf30b7/w:720/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%3A%20&quot;,&quot;hash&quot;:&quot;87def98eaa9ac99bf1437b8584c9fc7c372eaaca18e031e0d559056e0167658c&quot;,&quot;title&quot;:&quot;%E5%A4%A7%E4%BC%97%E7%9A%84%E5%BF%A7%E8%99%91&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1638.webp 720w,https://s.rfi.fr/media/display/ecda34ea-00a1-11ee-95ba-005056bf30b7/w:980/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%3A%20&quot;,&quot;hash&quot;:&quot;87def98eaa9ac99bf1437b8584c9fc7c372eaaca18e031e0d559056e0167658c&quot;,&quot;title&quot;:&quot;%E5%A4%A7%E4%BC%97%E7%9A%84%E5%BF%A7%E8%99%91&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1638.webp 980w"sizes="(max-width: 639px) calc(100vw - 32px), (max-width: 1023px) calc(100vw - 44px), (min-width: 1024px) 850px"/><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="人工智能会影响到人类的本质吗？" srcset="https://s.rfi.fr/media/display/ecda34ea-00a1-11ee-95ba-005056bf30b7/w:246/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%3A%20&quot;,&quot;hash&quot;:&quot;87def98eaa9ac99bf1437b8584c9fc7c372eaaca18e031e0d559056e0167658c&quot;,&quot;title&quot;:&quot;%E5%A4%A7%E4%BC%97%E7%9A%84%E5%BF%A7%E8%99%91&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1638.JPG 246w,https://s.rfi.fr/media/display/ecda34ea-00a1-11ee-95ba-005056bf30b7/w:388/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%3A%20&quot;,&quot;hash&quot;:&quot;87def98eaa9ac99bf1437b8584c9fc7c372eaaca18e031e0d559056e0167658c&quot;,&quot;title&quot;:&quot;%E5%A4%A7%E4%BC%97%E7%9A%84%E5%BF%A7%E8%99%91&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1638.JPG 388w,https://s.rfi.fr/media/display/ecda34ea-00a1-11ee-95ba-005056bf30b7/w:720/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%3A%20&quot;,&quot;hash&quot;:&quot;87def98eaa9ac99bf1437b8584c9fc7c372eaaca18e031e0d559056e0167658c&quot;,&quot;title&quot;:&quot;%E5%A4%A7%E4%BC%97%E7%9A%84%E5%BF%A7%E8%99%91&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1638.JPG 720w,https://s.rfi.fr/media/display/ecda34ea-00a1-11ee-95ba-005056bf30b7/w:980/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%3A%20&quot;,&quot;hash&quot;:&quot;87def98eaa9ac99bf1437b8584c9fc7c372eaaca18e031e0d559056e0167658c&quot;,&quot;title&quot;:&quot;%E5%A4%A7%E4%BC%97%E7%9A%84%E5%BF%A7%E8%99%91&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1638.JPG 980w"sizes="(max-width: 639px) calc(100vw - 32px), (max-width: 1023px) calc(100vw - 44px), (min-width: 1024px) 850px"loading="lazy"/></picture><button aria-label="播放影片"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 60 60"><path d="M30 0A30 30 0 1 1 0 30 30 30 0 0 1 30 0z" fill="#fff" opacity=".77"/><path d="M23.417 17.138v26.491l19.861-13.232z"/></svg></span></button><time>02:16</time></div><figcaption><span>人工智能会影响到人类的本质吗？</span>                <span>© Reuters</span>            </figcaption></figure></div><p>在今年五月的美国参议院听证会上，OpenAI的首席执行官萨姆·阿尔特曼警告美国参议员们，称“如果人工智能技术出了错，它可能会大错特错。我们希望对这一风险直言不讳，并希望与（美国）政府合作，以防止这种情况发生”。近期，美国联邦政府正在征求对人工智能法规的意见，希望能够通过法律来控制人工智能的危险，确定如何减少对隐私、公民自由和正当程序的威胁；英国计划在其人权、健康和安全以及竞争监管机构之间分担管理人工智能的责任，首相苏纳克曾表示，政府需要对人工智能拥有的“主权能力”，来管理国家所面临的安全风险；中国政府则正在寻求在国内启动人工智能法规，并在今年4月公布了管理生成人工智能服务的措施草案。中国政府希望各大科技公司在向公众推出产品之前，首先向政府提交安全评估报告。与此同时，北京还将支持龙头企业，打造挑战ChatGPT的人工智能模型；欧盟方面，主要立法者已就更严格的规则草案达成一致，以控制生成式人工智能，并提议禁止面部监控。欧洲议会还在本月对欧盟人工智能法案草案进行投票。</p><p>人工智能快速发展的能力，让一些近距离研究过它的专家开始警惕。被广泛誉为“人工智能教父”之一的计算机科学家杰弗里·辛顿在谷歌工作了10年，目前已离开谷歌。辛顿的工作被认为对当代人工智能系统的发展至关重要 : 他在1986年发布的一篇联合论文被业内视为支撑人工智能技术“神经网络”发展的里程碑。2018年，他获颁图灵奖，以表彰他在人工智能领域取得的突破。近期，他加入了越来越多的科技领袖，一同公开示警，称人工智能机器将获得比人类更高的智能，并可能控制地球。具体而言，辛顿谈到：“在过去的50年里，我一直在尝试在计算机上制作可以学习的模型，以了解大脑是如何学习的。而且我一直认为，大脑比我们拥有的计算机模型更优秀，我也一直认为通过使计算机模型更像大脑，我们可以对计算机系统做出改良。然而几个月之前，我顿悟了，我突然意识到，也许我们现在拥有的计算机模型实际上比大脑更优秀。如果真是这样，那么也许很快，计算机就会比我们更优秀。因此，有关超级智能的设想可能比我预期的要早来很多，这不会是很遥远的未来”。</p>    <div data-media-video-WBMZ89756-RFI-CN-20230609 data-wrapper-video-player data-show-hidden-video-player="WBMZ89756-RFI-CN-20230609"><divdata-hidden-video-player="WBMZ89756-RFI-CN-20230609"><video-playermedia-id="WBMZ89756-RFI-CN-20230609"video-type="youtube"source="https://www.youtube.com/embed/8pN0mKBPxoY"locale="zh-CN"type="main"video-id="8pN0mKBPxoY"playlist=""live=""embed_config = "{&quot;primaryThemeColor&quot;:&quot;#e2001a&quot;}"playsinline="1"autoplay    title=""                @ready="onPlayerReady"@play="onPlayerPlay"@ad_playing="onPlayerAdPlay"@ad_ending="onPlayerAdEnd"@paused="onPlayerPaused"@ended="onPlayerEnded"@cued="onPlayerVideoCued"@buffering="onPlayerBuffering"@destroyed="onPlayerDestroyed"><div><div></div></div></video-player></div><figure><div><picture><sourcetype="image/webp"srcset="https://s.rfi.fr/media/display/f28fbc62-00af-11ee-a0e0-005056bf30b7/w:246/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%5C%22%E6%95%99%E7%88%B6%5C%22%E4%B9%8B%E4%B8%80&quot;,&quot;hash&quot;:&quot;9bb35e54c28817b1c29d972d70ced351030b324443490a51b482f496ebbe8d9a&quot;,&quot;title&quot;:&quot;%E6%95%B2%E5%93%8D%E8%AD%A6%E9%92%9F&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1639.webp 246w,https://s.rfi.fr/media/display/f28fbc62-00af-11ee-a0e0-005056bf30b7/w:388/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%5C%22%E6%95%99%E7%88%B6%5C%22%E4%B9%8B%E4%B8%80&quot;,&quot;hash&quot;:&quot;9bb35e54c28817b1c29d972d70ced351030b324443490a51b482f496ebbe8d9a&quot;,&quot;title&quot;:&quot;%E6%95%B2%E5%93%8D%E8%AD%A6%E9%92%9F&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1639.webp 388w,https://s.rfi.fr/media/display/f28fbc62-00af-11ee-a0e0-005056bf30b7/w:720/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%5C%22%E6%95%99%E7%88%B6%5C%22%E4%B9%8B%E4%B8%80&quot;,&quot;hash&quot;:&quot;9bb35e54c28817b1c29d972d70ced351030b324443490a51b482f496ebbe8d9a&quot;,&quot;title&quot;:&quot;%E6%95%B2%E5%93%8D%E8%AD%A6%E9%92%9F&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1639.webp 720w,https://s.rfi.fr/media/display/f28fbc62-00af-11ee-a0e0-005056bf30b7/w:980/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%5C%22%E6%95%99%E7%88%B6%5C%22%E4%B9%8B%E4%B8%80&quot;,&quot;hash&quot;:&quot;9bb35e54c28817b1c29d972d70ced351030b324443490a51b482f496ebbe8d9a&quot;,&quot;title&quot;:&quot;%E6%95%B2%E5%93%8D%E8%AD%A6%E9%92%9F&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1639.webp 980w"sizes="(max-width: 639px) calc(100vw - 32px), (max-width: 1023px) calc(100vw - 44px), (min-width: 1024px) 850px"/><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="杰佛里·辛顿谈人工智能与控制权" srcset="https://s.rfi.fr/media/display/f28fbc62-00af-11ee-a0e0-005056bf30b7/w:246/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%5C%22%E6%95%99%E7%88%B6%5C%22%E4%B9%8B%E4%B8%80&quot;,&quot;hash&quot;:&quot;9bb35e54c28817b1c29d972d70ced351030b324443490a51b482f496ebbe8d9a&quot;,&quot;title&quot;:&quot;%E6%95%B2%E5%93%8D%E8%AD%A6%E9%92%9F&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1639.JPG 246w,https://s.rfi.fr/media/display/f28fbc62-00af-11ee-a0e0-005056bf30b7/w:388/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%5C%22%E6%95%99%E7%88%B6%5C%22%E4%B9%8B%E4%B8%80&quot;,&quot;hash&quot;:&quot;9bb35e54c28817b1c29d972d70ced351030b324443490a51b482f496ebbe8d9a&quot;,&quot;title&quot;:&quot;%E6%95%B2%E5%93%8D%E8%AD%A6%E9%92%9F&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1639.JPG 388w,https://s.rfi.fr/media/display/f28fbc62-00af-11ee-a0e0-005056bf30b7/w:720/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%5C%22%E6%95%99%E7%88%B6%5C%22%E4%B9%8B%E4%B8%80&quot;,&quot;hash&quot;:&quot;9bb35e54c28817b1c29d972d70ced351030b324443490a51b482f496ebbe8d9a&quot;,&quot;title&quot;:&quot;%E6%95%B2%E5%93%8D%E8%AD%A6%E9%92%9F&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1639.JPG 720w,https://s.rfi.fr/media/display/f28fbc62-00af-11ee-a0e0-005056bf30b7/w:980/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%5C%22%E6%95%99%E7%88%B6%5C%22%E4%B9%8B%E4%B8%80&quot;,&quot;hash&quot;:&quot;9bb35e54c28817b1c29d972d70ced351030b324443490a51b482f496ebbe8d9a&quot;,&quot;title&quot;:&quot;%E6%95%B2%E5%93%8D%E8%AD%A6%E9%92%9F&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1639.JPG 980w"sizes="(max-width: 639px) calc(100vw - 32px), (max-width: 1023px) calc(100vw - 44px), (min-width: 1024px) 850px"loading="lazy"/></picture><button aria-label="播放影片"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 60 60"><path d="M30 0A30 30 0 1 1 0 30 30 30 0 0 1 30 0z" fill="#fff" opacity=".77"/><path d="M23.417 17.138v26.491l19.861-13.232z"/></svg></span></button><time>02:44</time></div><figcaption><span>杰佛里·辛顿谈人工智能与控制权</span>                <span>© Reuters</span>            </figcaption></figure></div><p>“打个比方，如果你想去欧洲，你就先创建去机场这个子目标，然后你区解决这个子目标。对于任何你想要创建的复杂目标，你都可以先创建子目标。事实证明，对于几乎所有你想做的事情，有一个子目标是一本万利的：那就是获得更多的控制权。如果你获得了更多的控制权，就可以更轻松地实现其他的目标。所以一旦人工智能能够创造子目标 - 而且他们非常聪明 - 我想这些机器很快就会意识到，如果他们获得更多的控制权，他们就可以更容易地实现他们的目标。而一旦机器想获得控制权，事情就会开始变得对人们不利”。</p><p>“人工智能将是非常熟练的操控者，因为他们会从人类曾经做过的所有操控行为中学习。所以人工智能在操纵人类的方面会比人类强得多。他们将能够操纵我们，为所欲为。这就像你操纵一个两岁的孩子那样简单，而且这不是让机器人远离致命按钮就能解决的问题”。</p><p>“比如气候变化，你可以说，只要停止燃烧碳，一切都会好起来的。对某些人来说，这在政治上不太令人满意，但至少你可以看到解决方案的大概轮廓。如果我们能够获得真正高效的太阳能，那么我们就可以停止燃烧碳，一切都会好起来的。但是在人工智能风险上，我看不到类似的解决方案。我看不到说，‘只要这样做，一切都会好起来的’，这样的方案”。</p><p>“对于威胁人类的存在的设想，人工智能的发展可能会把我们全部消灭，就像核武器一样。而正是因为核武器有可能消灭所有人，所以全世界的人们可以一起合作，防止这种情况的发生。对于人工智能的威胁，我认为也许美国、中国、欧洲和日本可以一起合作，避免这种生存威胁的出现。但问题是，他们应该怎么做？无论如何，我认为停止开发是不可行的”。</p>    <div data-media-video-WBMZ89758-RFI-CN-20230609 data-wrapper-video-player data-show-hidden-video-player="WBMZ89758-RFI-CN-20230609"><divdata-hidden-video-player="WBMZ89758-RFI-CN-20230609"><video-playermedia-id="WBMZ89758-RFI-CN-20230609"video-type="youtube"source="https://www.youtube.com/embed/LKjc7JcwsFk"locale="zh-CN"type="main"video-id="LKjc7JcwsFk"playlist=""live=""embed_config = "{&quot;primaryThemeColor&quot;:&quot;#e2001a&quot;}"playsinline="1"autoplay    title=""                @ready="onPlayerReady"@play="onPlayerPlay"@ad_playing="onPlayerAdPlay"@ad_ending="onPlayerAdEnd"@paused="onPlayerPaused"@ended="onPlayerEnded"@cued="onPlayerVideoCued"@buffering="onPlayerBuffering"@destroyed="onPlayerDestroyed"><div><div></div></div></video-player></div><figure><div><picture><sourcetype="image/webp"srcset="https://s.rfi.fr/media/display/4b59d042-0067-11ee-81ac-005056bf30b7/w:246/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%B0%88&quot;,&quot;hash&quot;:&quot;09e8d3f786e2e682e7d1b67d20e2963ae3c83c7cb5e7a2b9a77177737c44090e&quot;,&quot;title&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%99%A9%E6%A2%A6&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1637.webp 246w,https://s.rfi.fr/media/display/4b59d042-0067-11ee-81ac-005056bf30b7/w:388/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%B0%88&quot;,&quot;hash&quot;:&quot;09e8d3f786e2e682e7d1b67d20e2963ae3c83c7cb5e7a2b9a77177737c44090e&quot;,&quot;title&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%99%A9%E6%A2%A6&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1637.webp 388w,https://s.rfi.fr/media/display/4b59d042-0067-11ee-81ac-005056bf30b7/w:720/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%B0%88&quot;,&quot;hash&quot;:&quot;09e8d3f786e2e682e7d1b67d20e2963ae3c83c7cb5e7a2b9a77177737c44090e&quot;,&quot;title&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%99%A9%E6%A2%A6&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1637.webp 720w,https://s.rfi.fr/media/display/4b59d042-0067-11ee-81ac-005056bf30b7/w:980/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%B0%88&quot;,&quot;hash&quot;:&quot;09e8d3f786e2e682e7d1b67d20e2963ae3c83c7cb5e7a2b9a77177737c44090e&quot;,&quot;title&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%99%A9%E6%A2%A6&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1637.webp 980w"sizes="(max-width: 639px) calc(100vw - 32px), (max-width: 1023px) calc(100vw - 44px), (min-width: 1024px) 850px"/><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="机器人Ameca所设想的人工智能噩梦" srcset="https://s.rfi.fr/media/display/4b59d042-0067-11ee-81ac-005056bf30b7/w:246/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%B0%88&quot;,&quot;hash&quot;:&quot;09e8d3f786e2e682e7d1b67d20e2963ae3c83c7cb5e7a2b9a77177737c44090e&quot;,&quot;title&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%99%A9%E6%A2%A6&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1637.JPG 246w,https://s.rfi.fr/media/display/4b59d042-0067-11ee-81ac-005056bf30b7/w:388/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%B0%88&quot;,&quot;hash&quot;:&quot;09e8d3f786e2e682e7d1b67d20e2963ae3c83c7cb5e7a2b9a77177737c44090e&quot;,&quot;title&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%99%A9%E6%A2%A6&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1637.JPG 388w,https://s.rfi.fr/media/display/4b59d042-0067-11ee-81ac-005056bf30b7/w:720/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%B0%88&quot;,&quot;hash&quot;:&quot;09e8d3f786e2e682e7d1b67d20e2963ae3c83c7cb5e7a2b9a77177737c44090e&quot;,&quot;title&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%99%A9%E6%A2%A6&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1637.JPG 720w,https://s.rfi.fr/media/display/4b59d042-0067-11ee-81ac-005056bf30b7/w:980/p:16x9/m:{&quot;brand&quot;:&quot;RFI&quot;,&quot;lang&quot;:&quot;CN&quot;,&quot;program&quot;:&quot;&quot;,&quot;cartouche&quot;:&quot;%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%B0%88&quot;,&quot;hash&quot;:&quot;09e8d3f786e2e682e7d1b67d20e2963ae3c83c7cb5e7a2b9a77177737c44090e&quot;,&quot;title&quot;:&quot;%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%99%A9%E6%A2%A6&quot;,&quot;id&quot;:&quot;04fb67c8-45fb-11ec-acac-005056bf30b7&quot;}/Capture-1637.JPG 980w"sizes="(max-width: 639px) calc(100vw - 32px), (max-width: 1023px) calc(100vw - 44px), (min-width: 1024px) 850px"loading="lazy"/></picture><button aria-label="播放影片"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 60 60"><path d="M30 0A30 30 0 1 1 0 30 30 30 0 0 1 30 0z" fill="#fff" opacity=".77"/><path d="M23.417 17.138v26.491l19.861-13.232z"/></svg></span></button><time>01:33</time></div><figcaption><span>机器人Ameca所设想的人工智能噩梦</span>                <span>© Reuters</span>            </figcaption></figure></div><p>另外一些人工智能研究专家认为，现在谈论来自人工智能的生存威胁，会分散人们对更紧迫问题的注意力。纽约大学计算机科学副教授兼人工智能中心主任朱丽亚·斯托言诺维奇表示：“在人工智能领域，我们产生了很多错误的信任，或者或错误的不信任。这也证明这些技术的成功，因为他们看起来、听起来真的很像人类，就好似他们有人类的意图一样”。</p><p>“然而如果从道德上免除人类对于控制人工智能的责任，就会出现很大的问题。有人说，‘现在我创造了这个智能的存在，它现在有了自己的想法，因此它可以自己做决定，它不再由我来控制‘。这是一个错误的、非常非常危险的思路”。</p><p>“我们需要所有人齐心协力才能控制人工智能系统，其中一个重要的组成部分就是监管和法律，我们需要监管来为这些系统的使用设置护栏。在部署人工智能系统之前，我们需要非常仔细地考虑哪些人会受到影响，以及他们以何种方式受到影响…例如在招聘、就业、掠夺性贷款、 获得住房、获得发展机会等这些领域”。</p><div data-selfpromo-newsletter></div><div data-selfpromo-app></div></div><div><div><div><div><span>作者：</span><a href="/cn/%E4%BD%9C%E8%80%85/%E5%91%A2%E5%96%83/" title="呢喃">呢喃</a></div></div></div></div>
