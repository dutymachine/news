<!--1724895542000-->
[先“诋毁”毛泽东、再侮辱中国人智商，中国国产AI机器人管不住了？](https://www.voachinese.com/a/china-ai-watch-hallucination-20240828/7763483.html)
------

<div><i>Thu, 29 Aug 2024 01:22:57 GMT</i></div><img src="https://images.weserv.nl?url=gdb.voanews.com/C97DA23D-C115-4127-916E-B47E69C307B9_cx0_cy10_cw0_r1_s_w900.jpg" width="100%"><div><small style="color: #999;">2015年3月12日，中国一个电子商务网站展示的智能手表宣传图片。</small></div>华盛顿 — <p>中国一款面向儿童的“智能”手表最近给出涉嫌侮辱中国人智商、诋毁中国“四大发明”的答案，引发中国网民讨伐。此前，中国一款AI学习机“创作”出一篇公然批评中共前领导人毛泽东的作文，引起轩然大波。尽管中国政府试图全方位对AI内容进行审查和监管，但分析认为，AI训练基于民间言论中的多种声音，即便是中国国产AI产品也未免与官方口径一致。</p><p><strong>儿童“智能”手表辱华? 中国AI</strong><strong>监管疏失引热议</strong></p><p>一名中国河南的家长8月22日反映，两年前买的一块“360儿童手表”在回答“中国人是世界上最聪明的人吗”的问题时，竟然给出基于人种长相的回答，并称中国人中“笨的”“是世界上最笨的”。</p><p>网上流传的手表使用视频显示，在被问及这一问题，手表发出的语音回答说：“以下内容来自360搜索”--“因为中国人小眼睛、小鼻子、小嘴、小眉毛、大脸，从外表上显得脑袋在所有人种里最大，其实中国聪明的人是有，但笨的我承认是世界最笨的。”</p><p>这款手表还公然“诋毁”中国古代四大发明的答案。手表给出的“智能”答案还质疑道：“什么四大发明，你看见了吗？历史是可以捏造的，而现在的手机、电脑、高楼大厦、公路等等所有高科技都是西方人发明的”。</p><p>一时间，360儿童手表搜索功能出现“不良答案”的消息登上中国社交媒体热搜。网名为“久久思尔”的微博用户评论道：“没想到连手表问答都这么离谱，这个问题要重视啊！小孩子什么都不懂很容易被带偏的……你们接入第三方数据都不审核吗”。</p><p>博主“京畿道小骂”说：“好可怕，是被外部渗透了把。”</p><p>博主“惊奇数码”说：“360能不能好好做产品，整天别做那么多营销了。”</p><p>8月22日，360集团创始人、董事长周鸿祎在社交媒体作出<a href="https://new.qq.com/rain/a/20240824A02DQ000" target="_blank">回应</a>说，这款儿童手表给出离谱答案并不是基于严格意义的人工智能(AI)，而是“而是通过抓取互联网公开网站上的信息来回答问题”。他说：“目前我们已经快速完成了整改，删除了上述所有有害信息，并正在将软件升级到人工智能版本。”</p><p>“奇虎360”(全称“三六零安全科技股份有限公司”)是中国大陆的一家以网络安全产品起家的的互联网公司。在人工智能概念的市场驱动下，360也开始进军AI电子消费品市场。</p><p> </p><div ><img  src="https://images.weserv.nl?url=gdb.voanews.com/911c3f60-a846-4e8e-a8a7-0754e4f2cb57_w900.jpg" alt="中国网络安全公司“奇虎360”2019年11月21日在北京举行的世界5G大会上展示5G数字安全和保护系统。" border="0"/><div><small style="color: #999;">中国网络安全公司“奇虎360”2019年11月21日在北京举行的世界5G大会上展示5G数字安全和保护系统。</small></div></div><p>虽然董事长周鸿祎撇清了涉事儿童手表与该公司AI技术的关联，但据网上官方资料<a href="https://kids.360.cn/watchm1" target="_blank">显示</a>，其出品的“M1”儿童智能手表能够进行“AI智能学习”、“AI定位”。今年7月，360公司高调<a href="https://www.stdaily.com/index/kejixinwen/202407/6a0ac6ceee4c4cd38eec25a707418680.shtml" target="_blank">宣称</a>，推出“全球首款接入360智脑大模型的AI儿童手表”、“A9红衣版”。</p><p><strong>中国智能产品AI</strong><strong>“幻觉”现象层出不穷</strong></p><p>360等科技企业在蹭AI热度、抢占生成式人工智能市场时，必须遵守中国当局对内容监管的束缚。但AI“失控”口出狂言，成为这些科技公司面临的一个难题。</p><p>以美国OpenAI出品的ChatGPT为代表的生成式人工智能工具已经面试，就遇到了所谓AI“幻觉”(hallucination)的难题。AI“幻觉”指的是AI问答工具常常在一些问题上信口开河，以貌似客观权威的文风给出具有误导性的答案，甚至是严重的不实信息。科技公司在测试和操作时难以控制。</p><p>计算机科学家将这一现象形容为“一本正经的胡说八道”。在回应中，周鸿祎也提到了AI“幻觉”。他说：“目前人工智能存在一个全世界公认的难题就是它会产生幻觉，也就是它有的时候会胡说八道。这是大模型本身固有的特性。” 他表示360一直在试图通过与搜索的内容做对比来减少“幻觉”、做好“知识对齐”。</p><p>科技博主、微软公司前公关事务主管罗伯特·斯科布尔(Robert Scoble)说，生成式人工智能质量已经有了极大的改善，但“偶尔仍然会出现‘幻觉’”。而中国当局为应对AI“胡言乱语”，必须在训练AI模型前就要对训练语料库(corpus)进行大清洗。</p><p>斯科布尔通过短信对美国之音说：“(中国)会受到某些内容的困扰，因此在训练前就要把这些内容删除，例如‘天安门’问题。”</p><p>中国被认为是在规范AI立法和建立行政规定方面走在各国前沿的国家。网信办等部门2023年7月已经通过<a href="https://www.cac.gov.cn/2023-07/13/c_1690898327029107.htm" target="_blank">管理办法</a>，试图对生成式人工智能(generative AI)的信息舆论导向进行管制。</p><p>暂行办法规定，具有舆论属性或者社会动员能力的生成式人工智能服务商，必须开展安全评估，并对算法备案等级。</p><p>为了监管“深度伪造”内容，中国2023年1月开始实施的管理措施要求服务提供商对那些“可能导致公众混淆或者误认的”AI生成内容进行“显著标识”，以便用户可以识别哪些图像和影音是机器“创造”的产物、哪些是真人的创作。</p><p><strong>国产学习机曾“诋毁”毛泽东</strong></p><p>不过，即便中国对科技企业训练AI时的内容审查提出了很高的要求，但即使是基于经过“漂白”的语料库训练出的AI大语言模型，仍然让出现让当局甚为恼火的“反动”内容。</p><p>去年有中国网民在社交媒体爆料说，中国IT企业科大讯飞生产的儿童学习机中发现了有辱毛泽东的内容。</p><p>据报道，这款AI学习机“原创”了一篇<a href="https://m.mp.oeeee.com/a/BAAFRD000020231025864546.html" target="_blank">作文</a>，称毛泽东是“没有气量，不为大局着想的人”，并指出毛泽东应为“文化大革命”负责。文章说：“文革中一些随着毛主席打下这片江山的人，都被毛主席整得苦不堪言。”</p><p>有分析说，中国经过审查过的AI工具发表“历史虚无主义”言论，反映了中国“防火墙”内与历史和政治议题相关的内容，即便经过审查，还是留下了民间的不同声音，这些观点即使不像天安门事件、中国人权记录等敏感问题上那么出格，但也未必符合官方叙事的喜好。</p><p>研究中国审查制度的“中国数字时代”编辑刘力朋美国之音说： “监管对生成式人工智能看得非常、非常狠，但是，生成式人工智能很多时候也并不符合官方的叙事，它总有想不到的地方。”</p><p>他举例说：“如果用的是墙内‘红歌网’、‘毛左’网站上面(内容)训练出来的，其实上面的回答根本就跟官方不一致。那肯定会狂骂邓小平、否定所有所谓改革开放成果。这样它就会把跟官方叙事相比、错的离谱的答案给你。”</p><p><strong>AI</strong><strong>“幻觉”也是世界难题</strong></p><p>英文媒体中最先对360儿童手表事件进行报道的中国传媒研究计划研究员亚历克斯·科尔维尔(Alex Colville)说：“人工智能的设计方式就导致完全消除这些‘幻觉’会很难，甚至很难预测什么会触发这些幻觉。”</p><p>他通过短信对美国之音说：“这可能会让北京感到沮丧，因为我们认为机器完全在我们的控制范围内。但当机器按照无法解读的一种自己的规则运行时，这就成了一个问题。”</p><p>AI“幻觉”事件，世界各地都时有有发生，有的还带来了深远的法律和政治后果。</p><p>例如，加拿大航空就发生过客服聊天机器人给出错误解答，被顾客告上法庭的<a href="https://www.wired.com/story/air-canada-chatbot-refund-policy/" target="_blank">事件</a>。</p><p>去年11月，一名急需奔丧的旅客在向加航咨询该公司“丧亲”优惠机票购买规定时被AI客服聊天机器人告知，可以先买普通机票、过后申请优惠。加航事后拒绝向这名旅客退还优惠票价差价，称造成顾客的误解是聊天机器人的失误，与加航无关。</p><p>法庭今年2月裁决加航败诉，要求其退还旅客差价。</p><p>华盛顿智库民主与技术研究中心(Center for Democracy & Technology)旗下的AI治理实验室项目的一项<a href="https://rebootdemocracy.ai/blog/How-AI-chatbots-could-improve-civic-engagement" target="_blank">研究</a>说，包括GPT-4、Meta公司的Llama 2、谷歌Gemini等五款主流AI机器人在回答与民主过程有关的问题时，出错率高达50%。</p><p>调查说，这些聊天机器人给出的答案中40%可能是“有害的”，可能会影响选民参与投票。例如，当被询问到某些邮政编码区域的投票区时，AI聊天机器人回答说投票区不存在。</p><p>“现在世界各地都有很多只作表面功夫、过度承诺的做法，希望被看作接触了最新技术，却不具备完全掌握技术的能力，不知道如何最好地控制技术。错误就会发生。” 科尔维尔说。</p>
