<!--1698980343000-->
[美中欧等共同签署AI治理宣言，但对如何确保AI不侵犯人权却没有共识](https://www.voachinese.com/a/us-china-uk-ai-summit-20231102/7339875.html)
------

<div><i>Fri, 03 Nov 2023 02:57:36 GMT</i></div><img src="https://images.weserv.nl?url=gdb.voanews.com/fbd1198f-2bd9-486c-a7a8-9de2078691c9_cx0_cy5_cw0_r1_s_w900.jpg" width="100%"><div><small style="color: #999;">2023年11月1日，在英国伦敦附近的布莱切利公园举行的英国人工智能安全峰会上，美国商务部长吉娜·雷蒙多（左）和英国科学、创新和技术部长米歇尔·唐兰（中）听取中国科技部副部长吴朝晖的讲话。</small></div><div><p>英国举办全球首届人工智能（AI）安全峰会11月2日（星期四）落幕。包括美国和中国在内的28个国家和欧盟共同签署了一份共同治理人工智能的宣言，但是，峰会对如何确保AI不会被滥用来侵犯人权却没有达成共识，宣言最后也没有提及人权。</p><p><strong>苏纳克邀中国参加为何引争议？</strong></p><div><p>鉴于中国利用科技进行网络审查、将AI技术用于监控少数族裔的记录，从英国决定邀请中国与会开始，中国就一直是争议的中心。英国首相里希·苏纳克（Rishi Sunak）不顾本国政客和人权团体的反对，邀请中国政府和科技企业参加英国AI安全峰会。星期四（11月2日），他在闭幕记者会上再次为邀请中国的决定辩护。</p></div><div><p>苏纳克说：“邀请中国不是一个容易的决定。事实上，很多人因此批评我，但我认为这是一个正确的长期决定，因为任何关于人工智能安全的严肃对话都必须让领先的AI国家参与进来。”</p></div><div><p>英国前首相伊丽莎白·特拉斯（Elizabeth Truss）是批评苏纳克这一决定的政客之一。她在峰会举行前致函苏纳克，呼吁撤销对中国的邀请。她说：“中国政府……一直利用和滥用科技来帮助它压迫数百万人，攻击自由和民主。北京政权对人工智能的态度与西方截然不同，将其视为国家控制的手段和国家安全的工具。”</p></div><div><p>她说：“鉴于中国对国际法的傲慢态度，没有一个有理智的人会指望中国将遵守这种峰会上达成的任何协议。”</p></div></div><div><div></div><div><div><p>不过，根据峰会日程，英国苏纳克在峰会第二天和一批政府、企业和专家进行“小范围”会面，进一步讨论如何应对AI技术的风险，并确保AI被“善意使用”。不过，中国不在和苏纳克会谈的“少数”国家代表之列。</p><p>科技业者对邀请中国参加这一峰会态度不一。特斯拉和太空探索技术公司（SpaceX）的CEO伊隆·马斯克（Elon Musk）星期四在峰会后与苏纳克对谈时说，将中国纳入有关AI安全的讨论是“必要的”（essential）。他说，在他看来，“中国愿意参与AI安全（的讨论）”，同时感谢苏纳克邀请中国，也感谢中国参加峰会。</p><p><strong>英国AI峰会宣言为何不提AI对人权的影响？</strong></p></div><div><div><p>峰会上与会各国签署的《布莱切利宣言》（ Bletchley Declaration ）阐述了前沿AI（frontier AI）技术可能对人类社会造成的风险。宣言签署方承诺为管控风险共同合作。宣言明确了各方对人工智能在网络安全、生物科技和假信息传播方面的担忧，但没有提及威权政府利用AI侵犯人权的问题。</p></div><div><p>分析人士认为，英国方面有意将峰会议题缩小在上述三个方面，目的是能让与会方达成具有实际内容的共识。</p></div><div><p>卡内基国际和平基金会亚洲项目研究员马特·希恩（Matt Sheehan）对美国之音说：“（英方）一开始就表示，他们希望解决前沿人工智能系统带来的安全风险。这显然抛却了很多绝对重要的人工智能伦理和其他形式的人工智能安全问题。但我确实认为，不要试图在一场峰会上去解决所有问题，这是明智的。”</p></div><div><p>“如果你想举办一场关于人工智能和人权的峰会，中国在西方国家的这些目标上并不兼容，也不会被邀请。”他说。</p></div><div><p>新美国安全中心(CNAS)技术与国家安全副研究员比尔·德雷克塞尔(Bill Drexel)则认为，通过峰会和外交方式敦促中国在AI应用方面尊重人权和保护公民权利虽然并不可行，但是，也许民主国家可以通过这样的接触建立一些以民主国家为导向的人工智能规范，并尝试在发展中国家建立这些规范，以“大棒加胡萝卜”的方法去“抑制中国开发更专制的人工智能工具，至少要抑制其他国家从中国购买这些工具”。</p></div><div><p>不过，他又说：“但就目前情况来看，中国非常致力于开发和使用这些工具。我不认为他们会因为任何形式的外交接触而在这方面有所让步。”他说。</p></div><div><p>在峰会召开的同时，在会场外，英国维吾尔人权组织“停止维吾尔种族灭绝”（Stop Uyghur Genocide）发起行动，在货车上展示“阻止中国以AI镇压维吾尔穆斯林”的标语，游走于伦敦国会大厦和布莱切利园峰会会场外，向民众讲述中国政府如何以高科技手段监控国民。</p></div><p><strong>美国继续防范前沿AI技术落入中国之手</strong></p><div><p>美国和中国都是AI技术强手、同时也是竞争对手，苏纳克对成功将这两个国家聚集在同一场论坛感到自豪。美国官方对英方邀请中国与会持欢迎态度。白宫科技政策办公室主任阿拉蒂·普拉巴卡尔（Arati Prabhkar）10月26日对<a href="https://www.washingtonpost.com/technology/2023/10/26/white-house-china-ai-uk-summit/" target="_blank">《华盛顿邮报》</a>表示，英方为了“在正确的谈判桌召集正确的人”做出了努力，而美方希望“在世界各个地区进行有益的对话”。</p><p>但美中同台不代表美国将放松技术管制，而是继续防范前沿AI等可能用于军事领域的两用科技落入中国之手。</p></div><div><p>美国政府加强在半导体芯片技术领域对中国的出口管制，目的之一就是堵截中国AI发展的技术渠道。负责实施出口管制的美国商务部的部长吉娜·雷蒙多（Gina Raimondo）星期三在峰会开场时与代表中国出席峰会的中国科技部副部长吴朝晖同台发表演讲。</p></div><div><p>雷蒙多在演讲中没有直接提到美中两国在AI领域的理念分歧，但提到了AI领域的大国竞争。</p></div><div><p>“即使各国竞争激烈，我们也能够而且必须寻求全球问题的全球解决方案。” 雷蒙多说：“这将需要在人工智能安全方面进行全球协调。这将需要每个国家承诺防止滥用，并确保危险的人工智能技术不会落入坏人之手。”</p></div><div><p>吴朝晖在雷蒙多之后发言。他说，中国提倡“以人类共同福祉为目标，保障社会安全、尊重人类权益，共同防范打击对AI技术的滥用和恶用”，强调“发展中国家在AI全球治理中的代表性和发言权”。</p></div><div><p>值得注意的是，美国拜登行政当局在英国AI峰会前发布了有关AI安全和发展的<a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/" target="_blank">行政命令</a>，明确提出美国的“对手和其他外国行为者”通过使用AI系统，可能对美国国防和情报机构、盟友和伙伴构成威胁，美国将继续努力应对。</p></div><div><p>美国企业研究所（AEI）客座高级研究员约翰·贝利（ John Bailey）在接受美国之音的采访时说，这份行政命令是为了“让外国对手无法获得前沿人工智能技术”。他说：“这份行政命令可以被视为美国试图剥夺中国拥有这类能力的政策的延续。”</p></div><div><p><strong>AI对人类的潜在危害远不止侵犯人权</strong></p></div><div><p>代表美国出席这场峰会的副总统卡马拉·哈里斯（Kamala Devi Harris )星期三呼吁各方重视人工智能对人类生存构成的威胁，这包括“AI引发的大规模网络攻击”和“可能危及数百万人生命的AI生物武器。</p></div><div><p>因人工神经网络和深度学习技术研究为誉为“AI教父”的加拿大科学家约书亚·本希奥（Yoshua Bengio）说，这些威胁并非危言耸听，也非对未来的想象，其中一些场景凭借目前的AI技术已经能够成真。</p></div><div><p>本西奥10月24日在英国<a href="https://www.chathamhouse.org/events/all/members-event/uk-ai-summit-what-can-it-achieve" target="_blank">查塔姆研究所</a>（Chatham House）举办的一场讨论会上说：“事实上，使用当前的人工智能系统（为化学武器设计有毒化学品）非常容易。你甚至不需要展望未来。”</p></div><div><p>本西奥警告说，AI可能对金融系统、就业和民主体系带来动荡，但人类目前并不清楚如何控制AI。</p></div><div><p>“与这些风险息息相关的是，我们现在不知道如何构建一个能够按‘预期’运行的人工智能系统；‘预期’指的是某些特定的任务，但也要求（AI）以符合我们的价值观、规范、道德和法律等方式运行。”</p></div></div></div></div>
