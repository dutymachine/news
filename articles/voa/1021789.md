<!--1695239944000-->
[AI监管呼声日渐强烈，美国AI立法为什么“落后”于中国？](https://www.voachinese.com/a/us-ai-regulations-20230920/7276756.html)
------

<div><i>Wed, 20 Sep 2023 19:45:28 GMT</i></div><img src="https://images.weserv.nl?url=gdb.voanews.com/08b55116-4ea5-4811-9959-3b46bd7430d6_r1_s_w900.jpg" width="100%"><div><small style="color: #999;">被放置在计算机主板上的AI字母。</small></div><p>人工智能（AI）技术飞速发展下，美国科技业和立法部门有越来越多的呼声建议设立专门的 “裁判”机构、为AI技术的使用建立许可制度。但专家指出，美国不太可能成立一个大权独揽的人工智能管理机构，美国AI监管步伐谨慎是为了保护科技创新的自由竞争环境和维护言论自由。</p><p><strong>为人工智能设“裁判”</strong><strong> </strong><strong>马斯克呼声引关注</strong></p><p>过去的一个星期，美国国会举行了至少三场与AI立法有关的讨论。最引人注目的是美国硅谷科技企业的多名重量级领袖聚集在华盛顿，在国会参议院多数党领袖查克·舒默（Chuck Schumer）的召集下，与国会议员在一场闭门会议中商讨政府如何对人工智能（AI）进行监管。</p><p>出席这场会议的科技界大佬包括谷歌、微软、Meta、OpenAI等AI技术公司的首席执行官（CEO）。舒默会后对记者说，他在会上提出“政府是否应该在监管人工智能中发挥作用”的问题，“所有人都举手（表示同意），虽然他们的观点不尽相同。”</p><p>特斯拉与太空探索技术公司（SpaceX）CEO伊隆·马斯克（Elon Musk）参加了参议院的这次闭门讨论会。他在会后对记者说，人工智能问题关乎人类“文明的风险”。马斯克呼吁，美国应该设立一个专门对人工智能进行“裁判”的机构。</p><div ><img  src="https://images.weserv.nl?url=gdb.voanews.com/01000000-0aff-0242-0c37-08dbb470b3a9_w900.jpg" alt="2023年9月13日，美国科技界领袖在华盛顿美国国会大厦参加由参议院多数党领袖查克·舒默主持的两党人工智能论坛。出席者包括特斯拉首席执行官埃隆·马斯克、Meta平台首席执行官马克·扎克伯格、Alphabet首席执行官桑达尔·皮查伊、OpenAI首席执行官萨姆·阿尔特曼、英伟达首席执行官黄仁勋、微软首席执行官萨蒂亚·纳德拉、IBM首席执行官阿文德·克里希纳和微软前首席执行官比尔·盖茨。" border="0"/><div><small style="color: #999;">2023年9月13日，美国科技界领袖在华盛顿美国国会大厦参加由参议院多数党领袖查克&#183;舒默主持的两党人工智能论坛。出席者包括特斯拉首席执行官埃隆&#183;马斯克、Meta平台首席执行官马克&#183;扎克伯格、Alphabet首席执行官桑达尔&#183;皮查伊、OpenAI首席执行官萨姆&#183;阿尔特曼、英伟达首席执行官黄仁勋、微软首席执行官萨蒂亚&#183;纳德拉、IBM首席执行官阿文德&#183;克里希纳和微软前首席执行官比尔&#183;盖茨。</small></div></div><p>专家说，人工智能的高速发展给美国和世界带来诸多难题，涉及国家安全、就业、假信息传播、偏见、民主价值等。设在旧金山的非政府组织人工智能安全中心（Center for AI Safety）的总监丹·亨德里克斯（Dan Hendrycks）警告，如果对人工智能的发展不加任何制约，人类社会将进入一种“极度依赖人工智能系统”的阶段。</p><p>他在布鲁金斯学会的一次<a href="https://www.brookings.edu/events/frontier-ai-regulation-preparing-for-the-future-beyond-chatgpt/" target="_blank">讨论会</a>上说，人类对AI失去控制，并非AI在设计中具有恶意，而是在追求速度和效率的竞争中，集体任由AI一次又一次地“胜出”，最终被人工智能取代。</p><p>他说：“不幸的是，随着人工智能系统变得越来越有竞争力，它们自然会在很多方面取代我们。”</p><p>“世界各国政府都在关注（人工智能）这项新技术，并试图弄清楚该怎么做。”美国乔治城大学安全与新兴技术中心（CSET）战略和基础研究拨款事务主任海伦·托纳（Helen Toner）通过电子邮件对美国之音说。</p><p>她说：“美国起步有些落后于中国和欧盟，但现在国会对发展出对AI的某种监管方法非常感兴趣。”</p><p>欧盟可望于今年通过的《人工智能法案》（AI Act）希望建立全球首个全面的人工智能监管计划，旨在确保推行到市场的AI应用安全、可信任。在“布鲁塞尔效应”下，欧盟的AI标准可能影响全球。</p><p>虽然中国的科技企业，包括阿里巴巴和百度，在部署类似于硅谷 ChatGPT 的生成式人工智能应用程序方面仍处于追赶状态，但中国在制定复杂人工智能法规方面被认为是领导者。近两年，中国提出多部法律法规，从深度伪造、算法、生成式AI等方面对相关技术的发布者提出监管要求。</p><p><strong>效仿中国建立</strong><strong>AI</strong><strong>许可证制度？</strong></p><p>不过，美国是否应该在AI监管方面追赶中国和欧盟，美国国内有许多不同声音。</p><p>虽然包括马斯克、OpenAI（ChatGPT的发布商）CEO山姆·阿尔特曼（Sam Altman）在内的科技界领军人物都呼吁建立专门的政府机构处理AI的复杂问题，甚至并对AI技术的应用采取许可制，但人工智能触及的领域庞大，立法者若希望通过出台一套包罗万象的法律对AI实行有意义的约束，难度可想而知。</p><p>共和党联邦参议员约翰·肯尼迪（John Kennedy）9月12日在一次参议院听证会上说：“大多数参议员对人工智能的细节的理解程度、他们的总体印象是，人工智能有非凡的潜力能让我们的生活变得更好，但前提是它一开始不会让我们的生活变得更糟。”</p><p>肯尼迪说，议员没有能力以有针对性的方式设计出有关AI监管的全面法案。“我认为我们更有可能迈出小步。”他说：“如果你拥有一个能够向消费者吐出人工内容的机器人，消费者有权知道它是由机器人生成的以及谁拥有该机器人。我认为这是一个很好的起点。”</p><p>肯尼迪参议员与民主党联邦参议员布莱恩·沙茨（Brian Schatz）合作推出<a href="https://www.govinfo.gov/app/details/BILLS-118s2691is" target="_blank">《人工智能标识法案》</a>（AI Labeling Act），要求科技公司对AI生成的内容进行标识、并告知消费者相关AI科技背后的所有者身份。</p><p>除了上述两位，其他议员们以跨党派的方式，推出多项监管人工智能的<a href="https://www.wired.com/story/senators-want-chatgpt-ai-to-require-government-license/" target="_blank">提案</a>。民主党参议员理查德·布卢门萨尔（Richard Blumenthal）和共和党参议员乔什·霍利（Josh Hawley）9月8日启动立法，希望建立一个专门监管AI的机构，要求企业在应用ChatGPT这样的大语言模型之前需要获得许可。</p><p>这项提案说，人脸识别等“高风险”人工智能应用的开发也需要政府许可，科技公司必须在部署前测试AI模型的潜在危害，披露出现问题的情况，并允许独立第三方对人工智能模型进行审计。</p><p>这一提议与中国近期提出的AI管理条例有相似之处。今年4月，负责互联网内容审查的中国网信办发布有关生成式人工智能（generative AI）服务管理的规定草案，草案内容包括，要求AI服务商在提供服务前经过政府的安全评估。草案第六条规定，利用生成式人工智能产品向公众提供服务前，必须向国家网信部门申报安全评估，并将算法备案登记。</p><p>在监管名目众多的加利福尼亚州，州参议员斯科特·威纳（Scott Wiener）本月推出<a href="https://time.com/6313588/california-ai-regulation-bill/" target="_blank">提案</a>，对算力达到一定高门槛的“前沿”人工智能系统提出监管要求，要求这些高等AI系统满足技术信息方面的透明度要求，为“未能采取适当预防措施”的单位和个人确立法律责任。加州是硅谷所在地，法案若通过，将对美国科技行业带来深远影响。</p><p><strong>对言论自由极其重视，美国对监管更为谨慎</strong></p><p>不过，也有批评者反对对AI进行集中监管，认为单独设立的“人工智能部”不太可能解决AI带来的诸多问题，对AI产品设立许可证制度将让那些熟悉政府运作的大企业收益，打压科技创新所需的行业竞争。</p><p>谷歌公司公开反对建立专门监管AI的政府机构。据CNBC<a href="https://www.cnbc.com/2023/06/13/google-challenges-openais-calls-for-government-ai-czar.html" target="_blank">报道</a>，谷歌公司今年6月在一封回应给美国国家标准技术研究所（NIST）的信函中说，谷歌支持分散式的监管方式，以“多层次、多利益相关者的方法” 治理人工智能。</p><p>乔治城大学安全与新兴技术中心（CSET）的托纳说：“许多美国立法者正在强调现有监管机构在处理其领域内的人工智能问题方面的作用，例如，美国食品药品管理局（FDA）管理医疗人工智能，美国交通部管理自动驾驶汽车。”</p><p>布鲁金斯学会人工智能和新兴科技倡议项目政策总监杰西卡·布兰特（Jessica Brandt）通过电子邮件对美国之音说：“自由民主国家面临的挑战是，既要确保人工智能以负责任的方式发展和部署，也要支持一个能吸引人才和投资的有活力的创新生态系统。”</p><p>纽约大学媒体技术教授纽曼不同意美国AI监管“落后”的说法。他对美国之音说：“美国式的监管通常没有欧洲和亚洲那么严格。长期以来，倾向于自由放任或最低限度的监管是美国制度的特点。”</p><p>纽曼是即将出版的新书《进化智能：技术将如何让我们变得更聪明》（<em>Evolutionary Intelligence: How Technology Will Make Us Smarter</em>）的作者。他说：“这是美国联邦和州对商业的态度的特点，即对监管持谨慎态度，担心监管会比监管机构最初的担心的更糟糕。”</p><p>ChatGPT等生成式人工智能工具可以独自“创作”文章、图片和视频，引发了有关假信息泛滥问题的担忧。但专家警告，在美国对这样的AI技术进行许可制，可能触及言论自由的保护问题。</p><p>牵头推动AI立法的参议院多数党领袖舒默强调，美国的AI监管必须体现对“美国民主与自由根基的保护”；中国多部涉及AI的法规都强调科技必须“体现社会主义核心价值观”。</p><p>“一个显而易见的重点是，中国的规则非常注重审查--他们不希望AI机器人宣扬那些政府从中国互联网上仔细删除过的信息。” 乔治城大学安全与新兴技术中心（CSET）的托纳说。</p><p>纽约大学媒体技术教授纽曼说：“语言模型涉及的许多内容都属于言论范畴。对言论发许可，进行事先限制（prior restraint），也就是在说话之前要获得许可，这与美国的传统背道而驰。”</p><p>纽曼提倡对AI监管采取一种“下游模式”。他说：“如果技术被用于非法目的，已经有了法律，惩罚肇事者和犯罪的法律已经成文。没有理由因为犯罪使用了不同的工具就去再写一部法律。”</p><p>“人工智能基本上是数学，你无法去监管数学。我认为监管者和政府官员出于一种合理的担忧和恐惧，认为事情可能会失控。”他说：“我希望，这种恐惧不会导致不适当的立法，限制美国在人工智能领域的创造力。”</p>
