<!--1680309544000-->
[聊天机器人引恐慌？马斯克带头呼吁AI研究怨崖勒马，中国不买账](https://www.voachinese.com/a/us-china-ai-pause-20230331/7031329.html)
------

<div><i>Sat, 01 Apr 2023 00:24:02 GMT</i></div><img src="https://images.weserv.nl?url=gdb.voanews.com/d450b897-7c5f-4a99-9d1b-aefe5810d357_r1_s_w900.jpg" width="100%"><div><small style="color: #999;"></small></div><p>特斯拉CEO马斯克日前带头号召人工智能（AI）研究机构暂停ChatGPT那样的大语言模型发展，反映出不少人对于AI发展速度失控的担忧甚至恐慌。这一获得超过两千多签名的倡议并未引起多数中国AI业者的兴趣。批评者说，美国AI研究机构若主动放慢AI发展，将给中国以可乘之机。</p><p><strong>GPT-4的出现令人不安</strong></p><p>基于AI大语言模型的聊天机器人ChatGPT去年年底推出后，其强大的语言表达和信息整理能力随即引发世人震惊。不久前，ChatGPT的研发机构、美国OpenAI实验室本月推出了功能更为强大的升级版本GPT-4，不仅能回答文字提问，还能分析图片信息。</p><p>更让科技观察人士感到震惊的是OpenAI于本月23日推出的GPT-4插件功能，让这一大语言模型实时接入互联网上的信息，甚至可以接入第三方应用程序。有人将GPT-4插件的重要性比喻成从传统手机到iPhone那样质的飞跃。</p><p>AI大语言模型发展“失控”，让许多科技业界人士感到不安。</p><p>“我对我的同事说，哇，这是（AI大语言模型）向前迈出的非常重要的一步。” 英国搜索引擎公司Mojeek首席执行官科林·海赫斯特（Colin Heyhust）在一次电话采访中，向美国之音形容他了解到插件功能时震惊的感受。</p><p>海赫斯特同其他逾千名科技界人士一道，签署了一封由美国生命未来研究所（Future of Life Institute）3月29日发起的<a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/" target="_blank">联名信</a>，呼吁所有AI实验室暂停脚步，在未来6个月停止训练比GPT-4更强大的AI系统，以发展出一套有关AI设计与研发的安全准则。</p><p>公开信说：“只有当我们确信其效果是积极的、风险是可控的时候，才可以去开发强大的人工智能系统。”</p><p>公开信得到了很多科技业大佬的响应，因此受到各方瞩目。联署人包括特斯拉CEO马斯克和加拿大人工神经网络和深度学习技术专家约书亚·本希奥（Yoshua Bengio）。马斯克是生命未来研究所的创始人之一。</p><p>公开信说，AI正在开始在一些任务上与人类展开竞争，对AI的极速发展提出了五大质疑：是否应该让机器在人类信息渠道中散步宣传和谎言？是否应该让所有工作（包括那些让人类具有成就感的工作）都自动化？是否应该培育出最终可能在数量和智力上超过人类、让人类过时并取代人类的非人类思维？是否应该冒着失去对人类文明控制的风险去开发AI？</p><p>有批评者指出，ChatGPT有时对一些问题会以充满自信的语气给出不实答案，提供错误信息。这种AI聊天机器人“胡言乱语“的现象被称为“幻觉”（Hallucination），形容的是人工智能的自信反应，反应了AI模型使用的的训练数据并不能证明输出的合理性。</p><p>“当你奔向一个可能有悬崖边缘的地方，你不应该加速。我认为目前这种情况正在发生。” 海赫斯特对美国之音说。</p><p>长期关注AI安全性的华盛顿智库新美国安全中心（CNAS）副总裁兼研究总监保罗·沙瑞尔（Paul Scharre）最近在接受美国之音采访时说，必须确保AI系统安全可靠。</p><p>他说：“如今，许多人工智能系统都存在非常严重的安全问题。它们往往会做出奇怪的事，我们需要在人工智能的安全方面做得更好，以确保我们正在推动的系统——无论是用于聊天机器人的商业系统还是军事硬件——都是安全可靠的，确保它们会做我们期望它们做的工作。”</p><p><strong>反对者：对</strong><strong>AI的恐慌已经失控</strong></p><p>以GPT为代表的AI大语言模型商业化趋势似乎已势不可挡。OpenAI的主要投资者微软公司本月宣布，将GPT-4的功能加入其Office套件，命名为Copilot（副驾驶）。ChatGPT爆红后，深陷危机感的谷歌公司也推出了自己的AI聊天软件BARD。</p><p>中国百度公司也在3月16日推出了人工智能聊天机器人“文心一言”（ERNIE）。虽然该产品的功能与ChatGPT相比让外界感到失望，但已经引发数万家中国企业的兴趣。</p><p>这封号召AI研究者悬崖勒马的公开信一经公布，就遭遇不少批评和质疑。批评者说，暂停发展AI将阻碍生产力，同时给美国在AI领域的竞争对手——中国和俄罗斯——以可乘之机。</p><p>美国国会参议员迈克·朗兹（Mike Rounds）认为公开信的倡议将让美国的人工智能进展落后“半年到一年”。这名参议院人工智能小组（Senate Artificial Intelligence Caucus）的共和党籍成员对<a href="https://www.foxnews.com/politics/musks-push-halt-ai-development-no-sense-unless-china-onboard-gop-senator-says" target="_blank">福克斯新闻网</a>表示：“除非中国、中国的共产党准备拿出证据证明他们也会做同样的举动，否则我担心我们将在六个月内限制我们推进人工智能的能力，而中国不会。”</p><p>技术传播者、科技作家罗伯特·斯科布尔（Robert Scoble）对美国之音说：“我们不仅是在本国内部在技术的自动化和获取更高利润方面竞争，我们也处于国与国的竞争之中。中国和美国，（在竞争中）胜出和强于其他国家速度的一方，它就会获取真正的生产力提升。”</p><p>信息技术与创新基金会副会长丹尼尔·卡斯特罗在公开信发表后立刻发表声明说，AI没有失控，失控的是人类对AI的恐慌。</p><p>卡斯特罗指出，很少公司会真正响应这一公开信的“休兵”号召。他对美国之音说：“即使一些少数的公司和政府这样做了，也不会是全球性的。中国已经明确表示，这（人工智能）是他们想要投资的领域，他们认为这是未来，俄罗斯也提出了类似的论点，没有理由去相信有人会真的暂停他们的发展。</p><p>“因此，他们这里的提议根本是不可行。如果从美国经济和国家安全利益的角度来看，这也是没道理的。为什么你要允许你的对手继续开发这项技术，而你却袖手旁观呢？”他反问。</p><p><strong>公开信签署人数过两千</strong><strong> </strong><strong>中国联署者寥寥无几</strong></p><p>截至发稿时，这封公开信已经获得2300多人联署。联署人中代表中国的业界人士寥寥无几。其中有中国科学院自动化研究所人工智能伦理与治理中心主任曾毅，以及中国人工智能学会成员、上海慧算医疗科技公司的刘静（音译）。</p><p>科技作家斯科布尔说，他多次访问中国，与中国科研人员有深入交谈。“他们与美国人在很多东西上的观点非常不同。（美国）自由分享信息的方式，中国就不一样了，相比美国他们受到更多审查。”</p><p>“这两个国家的意见可能会非常不同的……所以会有很多竞争……像ChatGPT那样的大语言模型，可以真正提高所在国的生产力。中国确实在这方面努力工作。”他说。</p><p>签署公开信的海赫斯特承认公开信的提议存在缺陷很明显。但他强调，公开信呼吁的“只是（限制）有关那些比GPT-4更强大的大语言模型，而并不是要阻止人工智能的工作。要清楚这一点。”</p><p>OpenAI的领导人表示，他们并未开始训练GPT-5模型。OpenAI首席执行官山姆·阿尔特曼（Sam Altman）在接受《华尔街日报》<a href="https://www.wsj.com/articles/elon-musk-other-ai-bigwigs-call-for-pause-in-technologys-development-56327f?mod=e2tw" target="_blank">采访</a>时表示，该公司长期以来一直将安全放在开发的首位，并在GPT-4发布前花了超过6个月的时间对其进行安全测试。</p><p>海赫斯特对美国之音说：“没有人指望（GPT模型研究）工作真的会在这六个月内停止，这封信更多的是关于开启一场严肃的对话，让对话进行。但人们需要发声，让更多的人参与进来。这在于提高人们的认识。”</p><br><hr><div>获取更多RSS：<br><a href="https://feedx.net" style="color:orange" target="_blank">https://feedx.net</a> <br><a href="https://feedx.best" style="color:orange" target="_blank">https://feedx.best</a><br></div>
