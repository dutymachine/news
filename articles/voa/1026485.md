<!--1679690346000-->
[生成式AI大爆发 台湾专家：对抗极权、守护真相成当务之急](https://www.voachinese.com/a/efforts-to-safeguard-truth-20230324/7020554.html)
------

<div><i>Fri, 24 Mar 2023 20:17:07 GMT</i></div><img src="https://images.weserv.nl?url=gdb.voanews.com/01000000-0aff-0242-b442-08db2ca32007_r1_s_w900.jpg" width="100%"><div><small style="color: #999;">位于台北的台湾人工智慧实验室创办人杜奕瑾（美国之音特约记者李贤拍摄）</small></div><p>生成式人工智能(AI)应用加速，近期在语音、影像和文本等领域都出现了应用现象。台湾专家预测，AI不仅将大幅颠复商业模式，在地缘政治剧变的今天，更将成为认知作战的最大工具。因此，国际社会若不积极对抗极权政府，言论自由恐被虚假消息的操作反噬。<br /><br />台湾事实查核基金会周五(3月24日)于台北举行纪录片《A Thousand Cuts》的特映会，该片讲述菲律宾著名记者、也是诺贝尔和平奖得主瑞萨(Maria Ressa)对抗菲律宾执政当局的滥权滥杀及挺身对抗虚假讯息的故事。</p><p>特映会后，基金会特别召开“守护真相，建立民主防线”的座谈会，多位与会的台湾专家尤其聚焦人工智能(AI)科技的应用及其对认知作战和新闻自由的冲击。</p><p><strong>认知战操作手法：外国势力、颠复政权及道德指控</strong></p><p>其中，位于台北的台湾大学新闻研究所名誉教授张锦华分析，极权政府操弄的认知战具共通性。她说，以菲律宾政府锁定菲律宾媒体《Rappler》为例，其破坏新闻内容和事实真相的手法有三大类型，一是扣上“煽动民族主义”的大帽子，指称媒体的负面报道都是“外国势力、外国公司或美国指使”；其二是诬陷媒体记者反政府，说他们“要政变、颠复政府”，更变相对他们扣上刑事犯罪的罪名；最后是诉诸道德标准，例如批评记者“说谎、放假消息、爱钱贪钱”等仇恨语言或操弄仇女言论等。</p><div ><img  src="https://images.weserv.nl?url=gdb.voanews.com/01000000-0a00-0242-f5fc-08db2ca32008_w900.jpg" alt="位于台北的台湾大学新闻研究所名誉教授张锦华（美国之音特约记者李贤拍摄）" border="0"/><div><small style="color: #999;">位于台北的台湾大学新闻研究所名誉教授张锦华（美国之音特约记者李贤拍摄）</small></div></div><p>张锦华直言，这些手法都是认知作战。她提醒各界，认清这些形式，才能在面对耸动性言论或报道时，觉察到认知作战的套路。</p><p>张锦华说，各界应借镜乌克兰于俄乌战事中打赢资讯战的启示。她说，战争一爆发，乌克兰立刻全面禁止亲俄媒体，以限制战时的新闻和言论自由，来防止俄罗斯的渗透。其次，俄军侵略下，“任何假讯息要立刻解构”，包括乌国主流媒体、民众、甚至全球协力查报假讯息，例如乌克兰总统泽连斯基投降的深伪影片、乌军自导自演布查大屠杀及持有生化武器等假消息，即使是亲乌克兰的假讯息也立即查核，以伸张公信力。</p><p><strong>生成式AI让认知战变本加厉?</strong></p><p>张锦华说，聊天机器人ChatGPT的出现，加上AI生成算图工具MidJourney和深伪技术等发展，让各界对其效应或许看法不一，但她引述美国事实查核研究机构NewsGuard共同执行长克罗维兹（Gordon Crovitz）的话称，“这个工具将成为有史以来最强大的错误讯息工具”，而且很难消除这个威胁。</p><p>张锦华说:“其实没有任何一种灵丹妙药可以消除这个威胁，当然有很多方法，媒体识读、政府的政策监管等等，这都是要去继续进行的。”</p><p>位于台北的台湾人工智慧实验室创办人杜奕瑾也于座谈会上表示，比起公正新闻之发布，部分人士操作虚假讯息的利益更大，导致公共论坛的消失、媒体营收能力的弱化，而最新出现的生成式AI科技，更使其散布虚假讯息的能力大增。就ChatGPT技术而言，杜奕瑾说:“它只要合理的，都有办法生成，你只要能够做出任何侦测的方法，我们都是可以训练AI模型，去把它骗过去。”他预期未来AI将被广泛运用，因此，真实报道的媒体记者若无法大量地传递正确消息，“我们就会被虚假消息给反噬。”</p><p>他说，脸书（Facebook）上有些程式自动产生的留言，虽然因技术不到位，而出现奇怪的符号或看不懂的语言。但这些围绕特定主题、不断生成的虚假内容，就是要疲劳轰炸阅听大众，使其转化为脑袋里的意象。</p><p><strong>杜奕瑾：保障真人言论 伸张数位人权</strong></p><div ><img  src="https://images.weserv.nl?url=gdb.voanews.com/01000000-0aff-0242-b442-08db2ca32007_w900.jpg" alt="位于台北的台湾人工智慧实验室创办人杜奕瑾（美国之音特约记者李贤拍摄）" border="0"/><div><small style="color: #999;">位于台北的台湾人工智慧实验室创办人杜奕瑾（美国之音特约记者李贤拍摄）</small></div></div><p>当生成式AI技术广泛应用到言论上，杜奕瑾认为，“不删除就是保障言论自由”的思维其实是错的。因为若不及时制止这些操作，“真人的言论就会被淹没”。他说，一般人发表意见，若引来一堆“人”辱骂，或使用大量的仇恨语言来反制其意见时，久而久之就会让大家不敢自由发言。</p><p>拥抱科技文明的同时，杜奕瑾说，保障“真人”的公共论坛空间，才能保障数位人权。他主张，应加强社交媒体平台的透明度分析，并支持第三方机构揭发虚假讯息的操作，這不同于社交媒体对仇恨言论的审查机制，尤其这些审查机制已经成为独裁者箝制言论的工具。</p><p><strong>强化媒体能力 </strong></p><p>面对假讯息操作和新闻媒体的危机，杜奕瑾呼吁，公共论坛或媒体应投入资源，保障“真人数位人权”。他说，脸书(Facebook)和推特(Twitter)每年都从中国和俄罗斯收到大量的广告收益，渗透的意味浓厚，因为这两国根本封禁人民使用脸书和推特。因此，我们必须强化公共论坛及新闻媒体的能力，才能保障民主。</p><p>杜奕瑾建议三项具体作法，第一，发布相应的法规，以提升社交媒体平台的透明度；第二，新闻内容的广告收益应合理分润至内容创作者，让致力深度报道的媒体能得到合理的利润，以维系运营；第三，面对生成式AI科技的发展，受众应提高数位素养，以洞察AI科技的破坏力，并探讨如何防范生成科技产制虚假消息的伦理问题。</p><p><strong>沈伯洋：对抗极权至关重要</strong></p><p>台北大学犯罪学研究所副教授沈伯洋也于座谈会上提醒，不论是社群平台或AI的应用，资讯倾斜和对抗极权才是问题根源。他说，指责“网军”是件危险的事，因为背后“一定有真人”的思维，让人容易忽略“假讯息操作不只是网军而已”的事实。</p><div ><img  src="https://images.weserv.nl?url=gdb.voanews.com/01000000-0aff-0242-6d11-08db2ca32007_w900.jpg" alt="台北大学犯罪学研究所副教授沈伯洋（美国之音特约记者李贤拍摄）" border="0"/><div><small style="color: #999;">台北大学犯罪学研究所副教授沈伯洋（美国之音特约记者李贤拍摄）</small></div></div><p>沈伯言解释，网军是公关公司操作的商业模式，以便放大特定的网络声量，但问题是“过度”渲染事态。例如，在俄罗斯媒体主持节目的美国广播记者Garland Nixon近期在推特发布，白宫有一个毁灭台湾计划，此谣言在台湾广为传播，但网军并未涉入其中，凸显出台湾媒体生态的不够健全，因为无法做到把关假讯息。他说，在政治公关和网军协同行为的发展过程中，媒体本该扮演把关的角色，但现在却反而成为无限放大各种侧翼声音的工具。又例如，中国的白纸运动非常重要，但部分台湾媒体竟少有报道。沈伯洋担心，在抖音陪伴下长大的新生代，受到偏颇资讯的影响，恐缺乏对中国的足够认识。</p><p>沈伯洋强调，针对新闻自由、人权保障或社群媒体影响，各国都面临相同的困境，但此困境在民主社会都有机会得到修正，但在独极权社会反而事态更为严重。</p><p>沈伯洋说:“所有的问题的根源其实是在极权，因为极权这件事情，它才是会有生命的威胁，它的司法可能不够独立，它的议会本身不够独立，它会放大所有的问题，而且它没有一个修复的机制。其实说真的，要怎么去对抗极权，我觉得，更为重要。”</p><p>他说，TikTok监控美国公民的问题，近期引起热议。美国打算全面封禁TikTok，原因就在于它与中国威权政府的关系，让人无法信任。TikTok就算把数据储存在美国，但母公司北京字节跳动还是中企，仍能配合中共，存取美国公民的个资。TikTok宣称将交出演算法，这或能提高其后台资讯存取的透明度，但无法完全解决这类社群媒体所衍生的诸多问题，因为美国人对其缺乏信任度。</p>
